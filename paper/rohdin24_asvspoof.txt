The Automatic Speaker Verification Spoofing Countermeasures Workshop (ASVspoof 2024)
31 August 2024, Kos, Greece

24

10.21437/ASVspoof.2024-4

BUTSystemsandAnalysesfortheASVspoof5ChallengeJohanRohdin1,2,LinZhang1,OldˇrichPlchot1,VojtˇechStanˇek1,DavidMihola1,JunyiPeng1,ThemosStafylakis2,DmitriyBeveraki2,AnnaSilnova1,JanBrukner1,Luk´aˇsBurget11BrnoUniversityofTechnology,2OmiliaConversationalIntelligence{rohdin,qzhang,iplchot}@fit.vutbr.cz,tstafylakis@omilia.comAbstractThispaperdescribestheBUTsubmittedsystemsfortheASVspoof5challenge,alongwithanalyses.Forthecon-ventionaldeepfakedetectiontask,weuseResNet18andself-supervisedmodelsfortheclosedandopenconditions,respec-tively.Inaddition,weanalyzeandvisualizedifferentcombina-tionsofspeakerinformationandspoofinginformationaslabelschemesfortraining.Forspoofing-robustautomaticspeakerverification(SASV),weintroduceeffectivepriorsandproposeusinglogisticregressiontojointlytrainaffinetransformationsofthecountermeasurescoresandtheautomaticspeakerverifi-cationscoresinsuchawaythattheSASVLLRisoptimized.1.IntroductionAutomaticspeakerverification(ASV)systemsarewidelyusedtoverifytheidentityofspeakers.However,ASVsystemsarealsovulnerabletospoofingattacks[1,2,3].Althoughthemainpurposeofgenerativemodelsistofacilitatepeople’slives,nottoattackbiometricmodelsorpresentfalseinformation,thead-vancementofgenerativemodelsposesanincreasedthreattobiometricsystemsandsociety.Thus,itisdesirabletoexploreanti-spoofingsystems(alsoknownascountermeasures-CMorpresentationattackdetection-PAD)todetectandpreventspoofingattacks.Toencourageresearcherstoworkonthisimportanttaskinthespeechprocessingfield,theASVspoof[4,5,6,7]challengehasbeenheldsince2015.Sofar,threedif-ferentspoofingscenarioshavebeendiscussedinpreviousyears:(1)physicalaccess(PA)forreplayattacks,(2)logicalaccess(LA)forspoofedspeechgeneratedbytext-to-speech(TTS)syn-thesisand/orvoiceconversion(VC)attacks,and(3)deepfake(DF)forstronglycompressedLAattacks.Thisyear’sASVspoof5[8]involvestwotracks.Track1,likeinpreviousyears,involvesconventionaldeepfakedetectionthatdiscriminatesbonafidespeechfromspoofedspeech.Forthemaindiscussedspoofingscenario,ASVspoof5combinedLAandDFbasedonadvancedTTS/VCsystemsandintroducedadversarialattacks(specificallyfocusingonMalafide[9]anditsupgradedversionMalacopula[10])totheunseenevaluationset.Track2inASVspoof5mergedwiththespoofing-robustauto-maticspeakerverification(SASV)[11]2022challenge,withanewlydefinedtask-agnosticmetric,a-DCF[12].Conveniently,newlyproposedscorefusionbasedonanon-linearcombina-tionofCMandASVlog-likelihoodratios(LLRs)afterscorecalibration[13]andasingleintegratedsystembasedonSKA-TDNN[14]areprovidedasbaselines.Thechallengealsode-finestwoconditionsineachtrack-closeandopen-dependingonwhetheritisallowedtouseexternaldata.Fortrack1closecondition,wefollowedtop-rankedteamsfrompreviousyearsandutilizedResNet18asoursubmittedsystem.Furthermore,weexploredtheinfluenceoftrainingwithspeakerlabelsincombinationwithspoofed/bonafidelabels.Asfortheopencondition,giventhepromisingperformanceofSSLmodelsforspoofdetection[15,16,17],wecompareddifferentSSLmodelsasfront-end.WeutilizedourpreviouslyproposedMulti-headFactorizedAttentivePooling(MHFA)[18]toeffi-cientlyaggregateinformationfromtransformerlayersthroughanattentionmechanism,whichshowedsuperiorresultscom-paredtoasimplepoolinglayer.Fortrack2,therearetwocommonapproaches:(1)score/embeddingfusion[19,20]betweentwoindependentASVandCM,or(2)asingleintegratingmodel[21,22]thatopti-mizesASVandCMsimultaneously.Amongthese,scorefu-sionismorewidelyusedasitismoreintuitiveandmakesthemodeldecisionmoreexplainable.Mostexistingscorefusionstudiesfocusonsimplescoresummation.However,inordertotakeadecisionthatminimizestheexpectedcostforatrial,anon-linearcombinationoftheCMandASVisnecessary[13].Inthiswork,weprovideamoregeneraltreatmentoftheSASVscoringproblem.WederivethegeneralSASVLLRandshowthattheoptimalSASVdecisionforanychoiceofcostparam-eterscanbetakenfromtheSASVLLRwherethepriorshavebeenreplacedbyeffectivepriors,whichareobtainedbyabsorb-ingthecostsofvariousincorrectdecisionsintotheoriginalpri-ors.WethenusetheseresultstojointlyoptimizethecalibrationoftheCMandASVscorestoprovideanaccurateSASVLLR.2.Systemfortrack1deepfakedetection2.1.TaskanddatabaseTrack1ofASVspoof5focusesonthestand-alonespeechdeepfakedetectiontask,distinguishingbonafidesamplesfromspoofedones,justlikeinpreviouscompetitions[4,5,6,7].ThedataofthischallengewerecollectedduringASVspoof5Phase1.TheoveralldatasetisbasedontheMultilingualLibrispeech(MLS)dataset(English-languagesubset)[23],andsyntheticdataarecollectedfromcommunityvolunteers.Eight,eight,andsixteenspoofingattacksareconsideredfortraining,development,andevaluationsets,respectively.Thereare400and785speakersinvolvedinthetraininganddevelopmentsetrespectively.Tomeasuretheperformanceofdeepfakedetec-tion,theminimumdetectioncostfunction(minDCF),thecostoflog-likelihoodratio(Cllr)[24],andtheequalerrorrate(EER)areconsideredintrack1ofthechallenge.Moredetailscanbefoundinthesummarypaperofthechallenge[8].2.2.ResNet18fortheclosedcondition2.2.1.DetailsofthesystemFortheclosedcondition,wechoseResNet18[25]asoursystemwithMUSAN[26]noisesubsetandroomimpulseresponsesfor
25

dataaugmentation,asitisthemostusedsystembytop-rankedteamsinthepreviousyears[27].Weuse80-dimensionalMel-filterbankwithawindowlengthof25msandaframeshiftof10ms.AfterextractingembeddingfromResNet18,weusethetemporalstatisticspoolinglayer,alinearlayerwith256units,aReLUactivationfunction,abatchnormalizationlayer,andan-otherlinearlayerwithsoftmaxactivationforcalculatingcross-entropylosswithK-classclassification.TheLikelihoodsforbonafide/spoofwerecomputedbysummingthelikelihoodsoverspeakersandspooftypeswhereapplicable,afterwhichtheLLRwerecomputed.Thisapproachmaynotbeidealbutduetotimeconstraintswedidnotexplorealternativeapproaches.Inthenextsubsection,wewillanalyzedifferentKbasedonwhetherandhowweutilizespeakerinformationforclassification.2.2.2.ComparisonondifferentlabelingschemesToexplorewhetherspeakerinformationcouldhelpdeepfakedetectionintheASVspoof5challenge,weanalyzeddiffer-entlabelschemesconsideringdifferentspeakeridentityandbonafide/spoofclassesinthissubsection.Thisismoti-vatedbyconflictingconclusionsinexistingstudies.Somestudiesproposethatsimultaneouslyoptimizingspeakerclas-sificationanddeepfakedetectionwouldenhancetherobust-nessofdeepfakedetection[28].Whereasothersclaimthatreducingspeakervariabilitywouldbebeneficialfordeep-fakedetection[29].WeexaminedfivetypesoflabelingschemesbasedonResNet18introducedintheprevioussubsec-tion.Three(spk-binspf,spk-mulspf,spk-onespf)oftheseschemesincludespeakeridentity,whiletheothertwo(mulspf,binspf)focusonbonafide/spoof(s)classification,asshownbelow.ThenumbersofclassesKforeacharean-notated,giventherearefourhundredspeakers,eightdifferentspoofingmethods(A01∼A08),andonebonafideinthetrain-ingset.•spk-binspf(K=800):ThelabelisacombinationofspeakerIDandbonafide/spoof,•spk-mulspf(K=3600):ThelabelisacombinationofspeakerIDandbonafide/A01/.../A08,•spk-onespf(K=401):ThelabelisspeakerIDincaseofbonafide,else“spoof,”•mulspf(K=9):Thelabelisbonafide/A01/.../A08,•binspf(K=2):Thelabelisbonafide/spoof,thesameasincommondeepfakedetection.Resultsusingtheabovefivelabelschemesonthedevelop-mentsetoftrack1areshowninTable1,andvisualizationoftheirembeddingspacesbyUMAP[30]areshowninFigure1.First,wefocusonthetrainingsetregardingtheseensce-nariotodiscussthreequestions:(1)Shouldweconsiderspeakerinformationforspoofedspeech?Figure1(a)to(c)showthemodelsconsideringspeakerID.Inthe(a)spk-binspfand(b)spk-mulspf,whichtreatspoofingmethodsforeachspeakerasindependentclasses,weobservethatalthoughsomebonafidesamplesareclusteredinthecenter,mostsamplesaremixedanddifficulttodistinguish.In(c)spk-onespf,afterweintegrateallspoofedsamplesasasinglespoofclasswithoutconsidering“spoofed”speakerin-formation,thespoofedspeechbeginstodistinguishfrombonafidespeech.ThismodelachievesthelowestEERandpromis-ingminDCFcomparedwithothermodels.ThishintsthatitischallengingtotrainthemodelwhenassigningspeakerIDtothespoofedspeech.Thiscouldbeduetothereducednumberofsamplesforeachclassortheconfusionintroducedbyspeakerinformationforspoofedspeech.Table1:ResultsofResNet18withdifferentlabelschemesonthedevelopmentsetoftrack1.IDModelminDCFEER(%)CllractDCF1spk-binspf0.240113.6402.65960.93492spk-mulspf0.270813.8180.79850.61293spk-onespf0.162411.8913.14820.77944mulspf0.181112.4565.43650.99785binspf0.137412.1562.63600.6720(2)Shouldweconsiderspeakerinformationforbonafidespeech?VisualizationoncomparingFigure1(b)vs.(d),and(c)vs.(e)showsthatwhenweremovespeakerinformationandfocusondeepfakedetectionasin(d)and(e),thesamplesaremoreclusteredaccordingtotheirbonafide/spooflabels.Thisisunderstandable,asthemodelsin(b)and(c)containspeakerin-formation,andthedifferencesbetweenspeakercharacteristicsmightbelargerthanthedifferencesbetweenspoofedandbonafidesamples,whichmakesitdifficulttolearnhowtodistinguishbonafidefromspoof.(3)Shouldweintegratedifferentspoofingmethods?Compar-ing(d)and(e),wecanobservethatintegratingdifferentspoof-ingmethodsasasinglespoofclasshelpsthemodeldistinguishspoofedsamplesfrombonafide.Giventhatwedidn’ttreatdif-ferentspoofingmethodsindependently,itisunderstandablethatA01toA06aremixed.Notably,A07andA08arestillwelldis-tinguishedfromotherseventhoughtheyaretrainedunderthesamelabel.Similarobservationscanbefoundin(c-d).Thisisacceptable,asA07isgeneratedbyFastPitch[31]andA08isgeneratedbyVITS[32],whicharedifferentcomparedtotheothersixspoofingmethodsbasedonGlowTTSandGradTTS.Next,wemovetothedevelopmentset,whichcontainsun-seenspoofingmethodsanddisjointspeakers.AcrossallfivelabelschemesinFigure1(a-e),weobservethatA11(Tacotron2[33]),A13(StarGANv2-VC[34])andA14(YourTTS[35])arewelldistinguishedinalllabelschemescomparedwithotherspoofingmethods.ThiscouldbebecauseA11,A13,andA14utilizedsimilarorthesamecomponentswithspoofingmeth-odsthatthemodelencounteredduringtraining.Forexam-ple,Tacotron2technologyappliedinA11isalsoutilizedbyA07(FastPitch[31])toestimatethedurationoftheinputsym-bols.YourTTSusedinA14isbuiltbaseduponVITS[32]thatisappliedbyA08ofthetrainingset.Thisshowsthatthemodelisstilllimitedtotheseenscenarios,anditsperformanceisrestrictedbythedegreeofmismatchfromthetrainingset.Meanwhile,A12(In-houseunit-selection)[8]isdifficulttodis-tinguishfromthebonafide,whichisunderstandableasunit-selectionselectingsegmentsfrombonafideutterancestocon-sistthedesiredspoofedspeech,anditisunseenduringtrain-ing.Morerobusttechnologyfordetectingsuchunit-selectionattacksisworthexploringinfuturework.Additionally,explor-ingadaptationmethodstohandlemismatchedscenariosmoreeffectivelyisessentialforfutureresearch.Finally,wesubmitthesystem5(ResNet18-binspf)thatusesbonafide/spoofclassesasourfinalsystemforthetrack1-closecondition.ItachievesminDCF=0.5809,actDCF=0.8537,Cllr=4.0994,andEER=23.34%intheevaluationset.2.3.PretrainedSSLwithMHFAfortheopenconditionSSLmodelshaveattractedattentioninthedeepfakespeechde-tectionareaduetotheirpromisingperformance[15,16,17].Therefore,weusedpretrainedSSLmodelsasourCMsystem
26

(a) spk-binspf(b) spk-mulspf(c) spk-onespf(d) mulspf(e) binspfTrainDev.TrainDev.Figure1:Embeddingspaceofdifferentlabelschemes.submittedtotrack1-open.Specifically,wecompareddifferentpretrainedSSLmodelsincludingWav2vec2model[36],WavLMmodel[37],Hubert[38],anddata2vec[39]asshowninTable2.AllSSLmodelsareintheirBaseversiongiventheprohibitionusingofLibriLightinASVspoofchallenge[8].Inaddition,whenweaggregatedhid-denfeaturesextractedfromtransformerlayersofSSLmodels,wecomparedlearnableweightedsum[40]withaveragepooling(AP)vs.MHFA[18].MHFAisourrecentlyproposedpoolingmethodthatutilizestwosetsofnormalizedlayer-wiseweightstogenerateattentionmapsandcompressedfeatures.Wefol-lowedtheconfigurationfromourpreviouspaper[18]withthenumberofheadssetas64.Duringtraining,onlytheparametersofMHFAwhilekeepingSSLmodelsfrozen.Nodataaugmen-tationwasappliedintheseexperiments.ResultsareshowninTable2.
27

Table2:PerformancesofpretrainedSSLmodels(Basever-sions)onthedevelopmentsetofTrack1-opencondition.IDModelminDCFEER(%)CllractDCF1Wav2vec2+AP0.13125.0940.29240.16742Wav2vec2+MHFA0.08483.3000.58760.10973HuBERT+MHFA0.249711.1640.83061.00004WavLM+MHFA0.14006.8810.82681.00005Data2vec+MHFA0.22318.4000.80670.27246Fusion2+40.07632.9740.878611.00007Fusion6+ResNet180.06933.0480.901591.0000Comparingsystems1and2,MHFAoutperformedsimpleAP.Comparing2∼5,Wav2vec2andWavLMachievebetterperformance.Thus,wesubmittedthesystem7–equalweightaveragingofmax-minnormalizedpredictionscoresfromsys-tems2,4fromTable2andsystem5fromTable1.Thefusedsystem7achievesminDCF=0.2573,actDCF=1.0000,Cllr=0.9955,EER=9.28%intheevaluationset.3.Systemfortrack23.1.TaskanddatabaseTrack2ofASVspoof5involvesaspoofing-robustautomaticspeakerverification(SASV)task[11].Thisisanewlyintro-ducedtrackthathasemergedinrecentyears,aimingtointe-grateASVandCMsystemsandacceptingthespeechonlyifitisspokenbythebonafidetargetspeaker.Thetraininganddevelopmentsetsarethesameasintrack1withtheadditionalwell-knownVoxceleb2[41]databasefromthespeakerverifica-tionfield.Voxceleb2provided5,994speakersfortraining.Formeasuringperformance,differentfromtheSASV2022[11],whichutilizesSASV-EERasthemainmetric,thisyear’schal-lengeusesthenewlyintroducedmina-DCF[12]astheprimarymetric,withmint-DCF[42]andt-EER[43]asthesupplementmetrics.Moredetailscanbefoundinthesummarypaperofthechallenge[8].3.2.ASVsystemsWebasedourASVsystemsontheResNetarchitecturebyfol-lowingtheexactrecipeswiththeVoxcelebdatasetfromtheWe-speakertoolkit1[44]whileomittingspeechandmusicpartsfromtheMUSANdatathatwerenotallowedtobeusedinthechallenge.WeexperimentedonResNet34,ResNet101,andResNet221withAdditiveAngularMargin(AAM)softmaxloss.Wecomparedmodelsw/andw/olargemarginfine-tuning.Asenrollmentembeddings,weusedtheaverageembeddingfrommultipleenrollmentutterances.Wealsoanalyzednor-malizingextractedembeddingsbysubtractingthemeanoftheASVspoof5trainset/voxceleb2devset.Forscoring,weusedsimplecosinesimilarity.TheresultsareshowninTable3.3.3.Spoofing-robustautomaticspeakerverificationsystemOurSASVsystemisbasedoncombiningtheCMLLRandtheASVLLRintoaSASVLLR,i.e.,theLLRforthehypotheses•HA(Accepthypothesis):Thespeechisbonafideandfromthetargetspeaker.•HR(Rejecthypothesis):HAisnottrue.1https://github.com/wenet-e2e/wespeakerTable3:EERs(%)ofASVsystemsonthedevelopmentsetofTrack2.IDModelLargeMarginMeanNorm.EER(%)1ResNet34✓-5.9352ResNet34✓ASVspoof5train5.6053ResNet34✓Voxceleb2dev.5.9524ResNet34-ASVspoof5train5.4645ResNet101-ASVspoof5train5.2336ResNet221-ASVspoof5train5.101Sinceforbinarydecisionproblems,theoptimaldecisioncanbetakenfromtheLLR,thisistheoptimalscoreforaSASVsystem.Undersomeassumptions,theSASVLLRcanbecom-putedfromtheLLRoftheCMsystem,theLLRoftheASVsys-tem,andthepriorsofthecostparameters.TheformulafortheresultingSASVLLRhasbeenprovidedbefore,e.g.,in[13]and[45].Here,wepresentaslightlymoregeneralformoftheLLRandintroducetheconceptofeffectivepriorsfortheSASVtask,inspiredbythisconceptinspeakerverification[46].Theuseofeffectivepriorsshowshowtomakeoptimaldecisionsinthescenarioswherethedifferenttypesoffalseaccepthavedifferentcosts,whichisnotthecaseinthisevaluation2butmaybeuse-fulinotherscenariosand,moreimportantlyforthisevaluation,enablesustodofusion/calibrationusinglogisticregression.Thedetailsofourapproachareprovidedinthefollowingsubsections.WedenotethespeechXandthepropertiesofthespeechasfollows:•B:speechisbonafide•S:speechisspoofed•T:speechisfromthetargetspeaker•N:speechisnotfromthetargetspeakerwhereBandSaredisjointandTandNaredisjoint.NotethatHA=(B,T)andHRistheunionof(B,N),(S,T)and(S,N)3.3.3.1.OptimalscoresanddecisionsGivensomespeechdata,X,theexpectedcostofrejectingatrialisCmissP(HA|X),whereCmissisthecostoffalserejection.Ifthecostofincorrectlyacceptingaspoofedutterance,Cfa,spoof,andincorrectlyacceptinganimpostor,Cfa,imp4,isthesame(asisthecaseinASVspoof5),theexpectedcostofacceptingatrialisCfaP(HR|X),whereCfa=Cfa,spoof=Cfa,imp.Theprob-lemisthenastandardbinarydecisiontheoryproblemforwhichtheoptimaldecisionistoacceptif(seee.g.theBOSARIStoolkitmanual[46])CmissP(HA|X)CfaP(HR|X)=CmissP(X|HA)P(HA)CfaP(X|HR)P(HR)>1⇔logP(X|HA)P(X|HR)>logCfaCmiss−logP(HA)P(HR).(1)AlthoughtheevaluationplandidnotexplicitlyaskparticipantstoprovideLLRsfortrack2,theaboveshowsthatusingLLRs2Bothfalseacceptanceofanimpostor(ASVfalseaccept)andfalseacceptanceofspoofedspeech(CMfalseaccept)havecost10inthisevaluation.3Whenwerefertospoofedspeechfromatarget/non-targetspeaker,wemeanspoofedspeechwithsimulatedcharacteristicssimilartothoseofthetruetarget/non-targetspeaker.4NotethatintheASVspoof5evaluationplan,thisisdenotedCfa.
28

andanappropriatethresholdleadstooptimaldecisions.53.3.2.LLRTheLLRisgivenbylogP(X|HA)P(X|HR)=logP(X|B,T)P(X|B,N)pBN+P(X|S,T)pST+P(X|S,N)pSN=−logP(X|B,N)pBN+P(X|S,T)pST+P(X|S,N)pSNP(X|B,T)=−log(cid:18)P(X|B,N)P(X|B,T)pBN+P(X|S,T)P(X|B,T)pST+P(X|S,N)P(X|B,T)pSN(cid:19),(2)where•pBN=P(B,N|HR)•pST=P(S,T|HR)•pSN=P(S,N|HR)whilepBT=P(B,T|HA)=1iskeptimplicit.ThefirsttermafterthefinalequalsigninEq.(2)isjusttheinvertedLLRforASVonbonafidespeechandthesecondtermisjustthein-vertedspeaker-dependentLLRforaCM.OurCMsystemsarespeaker-independent,whichisincorrectaccordingtotheaboveformulabuthopefullyagoodenoughapproximation.NotethattheLLRdependsonconditionalpriors,pBN,pSTandpSN.ThisiscommontoLLRsthatarecomposedofseveralLLRsforsim-plersubevents,see[47]and[48]fortwootherexamples.InmanySASVscenarios(includingthechallengeifweunder-standcorrectly),wedonotexpectspoofingofnon-targetspeak-ers,i.e.,pSN=0.3.3.3.EffectivepriorsAnalogouslytocommonpracticeinASV[46],itsimplifiesmatterstoconvertthecostparametersintoanequivalentsetofcostsparameters6whereCmiss=Cfa,spoof=Cfa,imp=Cfa,spoof,imp=1butwherethepriorsarereplacedwiththeeffectivepriors.Withgeneralcosts,weshallacceptthetrialifP(X|B,T)P(B,T)CmissP(X|B,N)P(B,N)Cfa,imp+P(X|S,T)P(S,T)Cfa,spoof+P(X|S,N)P(S,N)Cfa,spoof,imp>1.(3)BydividingthenumeratoranddenominatorbyZ=P(B,T)Cmiss+P(B,N)Cfa,imp+P(S,T)Cfa,spoof+P(B,N)Cfa,spoof,imp,(4)weobtainP(X|B,T)P′(B,T)P(X|B,N)P′(B,N)+P(X|S,T)P′(S,T)+P(X|S,N)P′(S,N)>1,(5)5Strictlyspeaking,wedonotneedtoprovidethethreshold,andtheLLRscouldbesubjectedtoanymonotonicallyrisingfunctionandstillbeoptimalforthechallengemetricsinceitdoesnotcareaboutcalibra-tion.6ContrarytoSection3.3.1,weherealsoincludespoofedimpostors.ThecostoffalseacceptanceofsuchtrialsisdenotedCfa,spoof,imp.where,e.g.,P′(B,N)=Cfa,impP(B,N)/Z,(6)andtheothereffectivepriors,P′(B,T),P′(S,T)andP′(S,N)aredefinedsimilarly.ThismeansthatthedecisionthatisoptimalaccordingtoIneq.(5)isalsooptimalaccordingtoEq.(3)andviceversa.Thus,wecanworkwithCmiss=Cfa,spoof=Cfa,imp=Cfa,spoof,imp=1andtheoriginalpri-orsreplacedbytheeffectivepriors,P′(·,·),whentakingdeci-sionsaswellaswhenoptimizingmodelsfortakingdecisionssuchascalibrationandfusionmodels.Inthisway,wecanhan-dlesituationswhenoriginally,e.g.,Cfa,spoof̸=Cfa,imp.InthecasewhenCfa,spoof=Cfa,imp,workingwitheffectivepriorsisstillhelpfulfortraining,e.g.,calibrationmodels(seethenextsubsubsection).3.3.4.Logisticregressionbasedcalibration/fusionLetpSN=0anddenotellrcm(X)=logP(X|B,T)P(X|S,T)(7)andllrasv(X)=logP(X|B,T)P(X|B,N),(8)thenllrsasv(X)=logP(X|HA)P(X|HR)=−log(cid:16)p′BNe−llrcm(X)+p′STe−llrasv(X)(cid:17)(9)Wenotethatalthoughtheprimarymetric,mina-DCF,iscali-brationinsensitive,i.e.,itdoesnotcarewhethertheSASVLLRiscalibrated,propercalibrationoftheCMandASVLLRisstillimportantformina-DCFduetothecomplexrelationbe-tweenthemandtheSASVLLRgivenbyEq.(9).CalibratingtherawCMandASVLLRs(denotedllrrawasvandllrrawcm)withaffinetransformations,weobtainthecorrectedSASVLLRllrsasv(X,˜a0,˜a1,˜c0,˜c1)=−log(cid:16)p′BNe−˜c1llrrawcm(X)−˜c0+p′STe−˜a1llrrawasv(X)−˜a0(cid:17).(10)Wethenlearnthecalibrationparameters˜a0,˜a1,˜c0and˜c1jointlywithlogisticregressionwiththethreeclasses,(B,T),(B,N)and(S,T),beingweightedaccordingtotheireffectivepriors,i.e.,˜a0,˜a1,˜c0,˜c1=argmina0,a1,c0,c1(cid:88)DP′(D)NDND(cid:88)i=1L(X,SD,a0,a1,c0,c1)(11)whereL(X,SD,a0,a1,c0,c1)=log(cid:16)1+e−SD(llrsasv(X,a0,a1,c0,c1)+τ)(cid:17),(12)D={(B,T),(B,N),(S,T)},NDisthenumberoftrialsforclassD,SD=(cid:26)1for(B,T)−1for(B,N)and(S,T)(13)
29

Table4:ImpactofcalibrationfortheSASVLLRoftrack2intermsofmina-DCFontheASVspoof5developmentset.NocalibrationreferstocombiningtheCMandASVLLRaccordingEq.(9),i.e.,withoutanycalibrationandCalibrationreferstocombiningtheCMandASVLLRaccordingEq.(10)withthecalibrationparametersoptimizedaccordingtoEq.(12).NocalibrationCalibration0.178740.16854Table5:Resultsofvarioussystemsontheclosedconditionoftrack2ontheASVspoof5developmentset.ThenumberundertheCMsystemheadingreferstotheIDinTable1andthenum-berundertheASVsystemheadingreferstotheIDinTable3.CMsystemASVsystemmina-DCFmint-DCFt-EER(%)120.168540.352348.196520.126960.208586.569550.125290.208585.977560.125270.209246.026Table6:ResultsofvarioussystemsontheopenconditionofTrack2ontheASVspoof5developmentset.ThenumberundertheCMsystemheadingreferstotheIDinTable2andthenum-berundertheASVsystemheadingreferstotheIDinTable3.CMsystemASVsystemmina-DCFmint-DCFt-EER(%)260.047610.188862.514760.072870.155732.026andτ=logP′(B,T)P′(B,N)+P′(S,T).(14)LogisticregressiononLLRisastandardapproachforcalibra-tionandfusioninspeakerverification[49]whichencouragesgoodcalibrationaswellasdiscrimination.3.3.5.ExperimentsWeimplementedthelogisticregressioncalibrationinPy-torch[50].Foroptimization,weuseditsL-BFGS[51]opti-mizerwithdefaultsettings.Theresultusingspk-binspfofTrackoneasCMLLRandsystem2ofTable1theASVLLRarepresentedinTable4.Wecanseethattheproposedcalibra-tionimprovesthemina-DCFwitharound1%absolute.Duetotimeconstraints,wehavenotevaluatedtheeffectofcalibrationforsystemsotherthanspk-binspf,norhavewecompareditwithalternativeapproachesforcombiningtheCMandASVLLR.Abriefdiscussionofsomeoftheconceptualaspectsisprovidedinthenextsubsectionwhilefurtherexperimentaleval-uationsandanalysisshouldbepartoffuturework.Theresultsfortheclosedconditionoftrack2areshowninTable5.Consistentwiththeresultsfortrack1,wecanseethatCMsystem5outperformsCMsystem1.TheASVsystemhasaveryminorimpactonmina-DCFbutalargerimpactont-EER.Fortheclosedconditionoftrack2,wesubmittedthesysteminthelastrow.Itachievesmina-DCF=0.389,mint-DCF=0.778,t-EER=20.850%intheevaluationset.Theresultsfortheopenconditionoftrack2areshowninTable6.Contrarytotrack1,thefusionofseveralCMsystemsdidnotimproveintheprimarymetricfortrack2.Duetolimitedtime,wedidnotexplorethisfurtherandsubmittedthesysteminthefirstrow.Itachievesmina-DCF=0.180,mint-DCF=0.543,t-EER=8.390%intheevaluationset.3.3.6.DiscussionEquation(9)isthesameas[13]and[45].Inthosepapers,itwassuggestedtotunep′BNandp′STwithagridsearch.Inaddition,discriminativecalibrationoftheCMandASVLLRwasdoneindividuallybeforecombiningthemtoformtheSASVLLRin[13].In[45],boththeASVLLRandtheCMLLRwerees-timatedbyagenerative(Gaussian)fusionoftherawCMandrawASVscores.Howeverwekeepp′BNandp′STasspecifiedbythecostparameters(theeffectiveversions)andinsteadjointlylearnaffinetransformationsofllrcmandllrasvthatoptimizestheSASVLLRontheleftsideofEq.(9).Afewpointscanbemade:•Mostcalibrationmethodsrarelyproducescoresthatarewell-calibratedatalloperatingpoints.JointoptimizationoftheCMandASVcalibrationshouldcalibratetheseLLRstobeoptimalfortheoperatingpointoftheSASVtask.Thisspeaksinfavorofourproposedmethod.•Tuningp′BNandp′STcorrespondstoadjustingtheoffsetsoftheCMandASVLLR.Thisislesspowerfulthanaffinetransformations.However,individualprecalibrationoftheCMandASVLLRfollowedbytuningofp′BNandp′STfortheSASVasin[13]and[45]taskcouldbesufficient.•Tuningparameterswithagridsearchasin[13]and[45]al-lowsoptimizingtheperformanceofDCFatonespecificop-eratingpoint.SincetheDCFofoneoperatingpointisnotacontinuousfunction,itcannotbeoptimizedbygradient-basedmethodssuchasL-BFGS.•Logisticregressioncorrespondstooptimizingthecalibrationforawiderangeofoperatingpointsinsteadoftheonespec-ifiedbyDCF[24].Thiscouldmakethescorelessoptimizedforthespecificoperatingpointbut,ontheotherhand,reducetheriskofoverfittingtothisspecificoperatingpoint.Theprosandconsofdifferentcalibration/fusionmethodsneedtobeanalyzedinfuturework.4.ConclusionThispaperdescribedBUTsystemsandanalysesfortheASVspoof5challenge.Fortrack1,weconstructedResNet18withanalysesondifferentspeakerandspoofinglabelschemesforthecloseconditionandpretrainedSSLmodelwithMHFAfortheopencondition.Fortrack2,wedefinedSASVLLRinamoregeneralformwithanintroducedconceptofeffectivepriors.IntroducingeffectivepriorsenablesoptimaldecisionfortheSASVtaskregardlessofcostparameters.Italsoenablescal-ibratingSASVLLRsaswellasevaluatingthequalityofsuchLLRswithcalibrationsensitivemetrics.5.AcknowledgementsThisworkwaspartlysupportedbytheEuropeanUnion’sHori-zonEuropegrantagreementNo.101135916“ELOQUENCE,”andbytheCzechMinistryofInteriorprojectNo.VB02000060“NABOSO.”WeacknowledgeVSB–TechnicalUniversityofOstrava,IT4InnovationsNationalSupercomputingCenter,CzechRepublic,forawardingthisprojectaccesstotheLUMIsupercomputer,ownedbytheEuroHPCJointUndertaking,hostedbyCSC(Finland)andtheLUMIconsortiumthroughtheMinistryofEducation,YouthandSportsoftheCzechRepublicthroughthee-INFRACZ(grantID:90254).
30

6.References[1]NicholasEvans,TomiKinnunen,andJunichiYamagishi,“Spoofingandcountermeasuresforautomaticspeakerverification.,”inProc.Interspeech,2013,pp.925–929.[2]TimRing,“Europol:theaihackerthreattobiometrics,”BiometricTechnologyToday,vol.2021,no.2,pp.9–11,2021.[3]AntonFircandKamilMalinka,“Thedawnofatext-dependentsociety:deepfakesasathreattospeechveri-ficationsystems,”inProc.ACM/SIGAPPSAC,2022,p.1646–1655.[4]ZhizhengWu,TomiKinnunen,NicholasEvans,JunichiYamagishi,CemalHanilc¸i,MdSahidullah,andAleksandrSizov,“ASVspoof2015:theFirstAutomaticSpeakerVer-ificationSpoofingandCountermeasuresChallenge,”inProc.Interspeech,2015,pp.2037–2041.[5]TomiKinnunen,MdSahidullah,H´ectorDelgado,Massi-milianoTodisco,NicholasEvans,JunichiYamagishi,andKongAikLee,“TheASVspoof2017Challenge:Assess-ingtheLimitsofReplaySpoofingAttackDetection,”inProc.Interspeech,2017,pp.2–6.[6]AndreasNautsch,XinWang,NicholasEvans,TomiH.Kinnunen,VilleVestman,MassimilianoTodisco,H´ectorDelgado,MdSahidullah,JunichiYamagishi,andKongAikLee,“ASVspoof2019:Spoofingcountermea-suresforthedetectionofsynthesized,convertedandre-playedspeech,”IEEETransactionsonBiometrics,Be-havior,andIdentityScience,vol.3,no.2,pp.252–265,2021.[7]JunichiYamagishi,XinWang,MassimilianoTodisco,MdSahidullah,JosePatino,AndreasNautsch,XuechenLiu,KongAikLee,TomiKinnunen,NicholasEvans,andH´ectorDelgado,“ASVspoof2021:acceleratingprogressinspoofedanddeepfakespeechdetection,”inProc.ASVspoofWorkshop,2021,pp.47–54.[8]XinWang,H´ectorDelgado,HemlataTak,Jee-weonJung,Hye-jinShim,MassimilianoTodisco,IvanKukanov,XuechenLiu,MdSahidullah,TomiKinnunen,NicholasEvans,KongAikLee,andJunichiYamagishi,“ASVspoof5:Crowdsourcedspeechdata,deepfakes,andadversarialattacksatscale,”inProc.ASVspoofWorkshop2024(ac-cepted).[9]MichelePanariello,WanyingGe,HemlataTak,Massim-ilianoTodisco,andNicholasEvans,“Malafide:anoveladversarialconvolutivenoiseattackagainstdeepfakeandspoofingdetectionsystems,”inProc.Interspeech,2023,pp.2868–2872.[10]MassimilianoTodisco,MichelePanariello,XinWang,HectorDelgado,Kong-AikLee,andNicholasEvans,“Malacopula:Adversarialautomaticspeakerverificationattacksusinganeural-basedgeneralisedhammersteinmodel,”inProc.ASVspoofWorkshop2024(accepted).[11]JeeweonJung,HemlataTak,HyejinShim,Hee-SooHeo,Bong-JinLee,Soo-WhanChung,Ha-JinYu,NicholasEvans,andTomiKinnunen,“SASV2022:TheFirstSpoofing-AwareSpeakerVerificationChallenge,”inProc.Interspeech,2022,pp.2893–2897.[12]HyejinShim,JeeweonJung,TomiKinnunen,NicholasEvans,Jean-Franc¸oisBonastre,andItshakLapidot,“a-DCF:anarchitectureagnosticmetricwithapplicationtospoofing-robustspeakerverification,”inProc.Odyssey,2024,pp.158–164.[13]XinWang,TomiKinnunen,LeeKongAik,Paul-GauthierNo´e,andJunichiYamagishi,“Revisitingandimprovingscoringfusionforspoofing-awarespeakerverificationus-ingcompositionaldataanalysis,”inProc.Interspeech,2024,p.(accepted).[14]SungHwanMun,HyejinShim,HemlataTak,XinWang,XuechenLiu,MdSahidullah,MyeonghunJeong,MinHyunHan,MassimilianoTodisco,KongAikLee,JunichiYamagishi,NicholasEvans,TomiKinnunen,NamSooKim,andJeeweonJung,“TowardsSingleInte-gratedSpoofing-awareSpeakerVerificationEmbeddings,”inProc.Interspeech,2023,pp.3989–3993.[15]XinWangandJunichiYamagishi,“InvestigatingSelf-SupervisedFrontEndsforSpeechSpoofingCountermea-sures,”inProc.Odyssey,2022,pp.100–106.[16]HemlataTak,MassimilianoTodisco,XinWang,JeeweonJung,JunichiYamagishi,andNicholasEvans,“Auto-maticSpeakerVerificationSpoofingandDeepfakeDetec-tionUsingWav2vec2.0andDataAugmentation,”inProc.Odyssey,2022,pp.112–119.[17]PiotrKawa,MarcinPlata,MichałCzuba,PiotrSzyma´nski,andPiotrSyga,“ImprovedDeepFakeDetec-tionUsingWhisperFeatures,”inProc.Interspeech,2023,pp.4009–4013.[18]JunyiPeng,OldˇrichPlchot,ThemosStafylakis,LadislavMoˇsner,Luk´aˇsBurget,andJanˇCernock´y,“Anattention-basedbackendallowingefficientfine-tuningoftrans-formermodelsforspeakerverification,”inProc.SLT,2023,pp.555–562.[19]HyejinShim,HemlataTak,XuechenLiu,etal.,“Base-lineSystemsfortheFirstSpoofing-AwareSpeakerVerifi-cationChallenge:ScoreandEmbeddingFusion,”inProc.Odyssey,2022,pp.330–337.[20]XingmingWang,XiaoyiQin,YikangWang,YunfeiXu,andMingLi,“TheDKU-OPPOSystemforthe2022Spoofing-AwareSpeakerVerificationChallenge,”inProc.Interspeech,2022,pp.4396–4400.[21]ChangZeng,LinZhang,MengLiu,andJunichiYam-agishi,“Spoofing-AwareAttentionbasedASVBack-endwithMultipleEnrollmentUtterancesandaSamplingStrategyfortheSASVChallenge2022,”inProc.Inter-speech,2022,pp.2883–2887.[22]AlexanderAlenin,NikitaTorgashov,AntonOkhotnikov,RostislavMakarov,andIvanYakovlev,“ASubnetworkApproachforSpoofingAwareSpeakerVerification,”inProc.Interspeech,2022,pp.2888–2892.[23]VineelPratap,QiantongXu,AnuroopSriram,GabrielSynnaeve,andRonanCollobert,“MLS:ALarge-ScaleMultilingualDatasetforSpeechResearch,”inProc.In-terspeech,2020,pp.2757–2761.[24]NikoBr¨ummerandJohanduPreez,“Application-independentevaluationofspeakerdetection,”ComputerSpeech&Language,vol.20,no.2,pp.230–275,2006.[25]KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun,“Deepresiduallearningforimagerecognition,”inProc.CVPR,2016,pp.770–778.
31

[26]DavidSnyder,GuoguoChen,andDanielPovey,“MU-SAN:Amusic,speech,andnoisecorpus,”arXivpreprintarXiv:1510.08484,2015.[27]XuechenLiu,XinWang,MdSahidullah,JosePatino,H´ectorDelgado,TomiKinnunen,MassimilianoTodisco,JunichiYamagishi,NicholasEvans,AndreasNautsch,etal.,“ASVspoof2021:Towardsspoofedanddeepfakespeechdetectioninthewild,”IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,vol.31,pp.2507–2522,2023.[28]YichuanMoandShilinWang,“Multi-tasklearningim-provessyntheticspeechdetection,”inProc.ICASSP,2022,pp.6392–6396.[29]GajanSuthokumar,VidhyasaharanSethu,KaavyaSriskandaraja,andEliathambyAmbikairajah,“Adversar-ialmulti-tasklearningforspeakernormalizationinreplaydetection,”inProc.ICASSP,2020,pp.6609–6613.[30]LelandMcInnes,JohnHealy,NathanielSaul,andLukasGrossberger,“UMAP:Uniformmanifoldapproximationandprojection,”TheJournalofOpenSourceSoftware,vol.3,no.29,pp.861,2018.[31]AdrianŁa´ncucki,“Fastpitch:Paralleltext-to-speechwithpitchprediction,”inProc.ICASSP,2021,pp.6588–6592.[32]JaehyeonKim,JungilKong,andJuheeSon,“Conditionalvariationalautoencoderwithadversariallearningforend-to-endtext-to-speech,”inProc.ICML,2021,pp.5530–5540.[33]JonathanShen,RuomingPang,RonJWeiss,MikeSchuster,NavdeepJaitly,ZonghengYang,ZhifengChen,YuZhang,YuxuanWang,RjSkerrv-Ryan,etal.,“Naturalttssynthesisbyconditioningwavenetonmelspectrogrampredictions,”inProc.ICASSP,2018,pp.4779–4783.[34]YinghaoAaronLi,AliZare,andNimaMesgarani,“StarGANv2-VC:ADiverse,Unsupervised,Non-ParallelFrameworkforNatural-SoundingVoiceConversion,”inProc.Interspeech,2021,pp.1349–1353.[35]EdressonCasanova,JulianWeber,ChristopherDShulby,ArnaldoCandidoJunior,ErenG¨olge,andMoacirAPonti,“YourTTS:Towardszero-shotmulti-speakerttsandzero-shotvoiceconversionforeveryone,”inProc.ICML,2022,pp.2709–2720.[36]AlexeiBaevski,HenryZhou,AbdelrahmanMohamed,andMichaelAuli,“wav2vec2.0:aframeworkforself-supervisedlearningofspeechrepresentations,”inProc.NeurIPS,2020,p.12.[37]SanyuanChen,ChengyiWang,ZhengyangChen,andet.al.,“WavLM:Large-scaleself-supervisedpre-trainingforfullstackspeechprocessing,”IEEEJournalofSelectedTopicsinSignalProcessing,vol.16,no.6,pp.1505–1518,Oct.2022.[38]Wei-NingHsu,BenjaminBolte,Yao-HungHubertTsai,KushalLakhotia,RuslanSalakhutdinov,andAbdelrah-manMohamed,“Hubert:Self-supervisedspeechrepre-sentationlearningbymaskedpredictionofhiddenunits,”IEEE/ACMtransactionsonaudio,speech,andlanguageprocessing,vol.29,pp.3451–3460,2021.[39]AlexeiBaevski,Wei-NingHsu,QiantongXu,ArunBabu,JiataoGu,andMichaelAuli,“Data2vec:Ageneralframe-workforself-supervisedlearninginspeech,visionandlanguage,”inProc.ICML,2022,pp.1298–1312.[40]ShuwenYang,Po-HanChi,andet.al.,“SUPERB:SpeechProcessingUniversalPERformanceBenchmark,”inProc.Interspeech,2021,pp.1194–1198.[41]JoonSonChung,ArshaNagrani,andAndrewZisserman,“VoxCeleb2:DeepSpeakerRecognition,”inProc.Inter-speech,2018,pp.1086–1090.[42]TomiKinnunen,H´ectorDelgado,NicholasEvans,KongAikLee,VilleVestman,AndreasNautsch,Massim-ilianoTodisco,XinWang,MdSahidullah,JunichiYamag-ishi,etal.,“Tandemassessmentofspoofingcountermea-suresandautomaticspeakerverification:Fundamentals,”IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,vol.28,pp.2195–2210,2020.[43]TomiHKinnunen,KongAikLee,HemlataTak,NicholasEvans,andAndreasNautsch,“t-EER:Parameter-freetan-demevaluationofcountermeasuresandbiometriccom-parators,”IEEETransactionsonPatternAnalysisandMa-chineIntelligence,2023.[44]HongjiWang,ChengdongLiang,ShuaiWang,ZhengyangChen,BinbinZhang,XuXiang,YanleiDeng,andYanminQian,“Wespeaker:Aresearchandproductionorientedspeakerembeddinglearningtoolkit,”inProc.ICASSP.IEEE,2023,pp.1–5.[45]MassimilianoTodisco,H´ectorDelgado,KongAikLee,MdSahidullah,NicholasEvans,TomiKinnunen,andJu-nichiYamagishi,“IntegratedPresentationAttackDetec-tionandAutomaticSpeakerVerification:CommonFea-turesandGaussianBack-endFusion,”inProc.Inter-speech,2018,pp.77–81.[46]NikoBr¨ummerandEdwarddeVilliers,“TheBOSARISToolkit:Theory,algorithmsandcodeforsurvivingthenewDCF,”arXivpreprintarXiv:1304.2865,2013.[47]NikoBr¨ummer,“LLRtransformationforSRE’12,”Agni-tioResearch,2012.[48]YosefSolewicz,NoaCohen,JohanRohdin,SrikanthMadikeri,andJanHonzaˇCercnock´y,“SpeakerRecogni-tiononMono-ChannelTelephonyRecordings,”inProc.Odyssey,2022,pp.193–199.[49]NikoBrummer,LukasBurget,JanCernocky,OndrejGlembek,FrantisekGrezl,MartinKarafiat,DavidA.vanLeeuwen,PavelMatejka,PetrSchwarz,andAlbertStrasheim,“FusionofheterogeneousspeakerrecognitionsystemsintheSTBUsubmissionfortheNISTspeakerrecognitionevaluation2006,”IEEETransactionsonAu-dio,Speech,andLanguageProcessing,vol.15,no.7,pp.2072–2084,2007.[50]AdamPaszke,SamGross,etal.,“Pytorch:Animperativestyle,high-performancedeeplearninglibrary,”inProc.NeurIPS,2019,pp.8024–8035.[51]DongCLiuandJorgeNocedal,“Onthelimitedmemorybfgsmethodforlargescaleoptimization,”Mathematicalprogramming,vol.45,no.1,pp.503–528,1989.