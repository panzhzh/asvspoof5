The Automatic Speaker Verification Spoofing Countermeasures Workshop (ASVspoof 2024)
31 August 2024, Kos, Greece

1

10.21437/ASVspoof.2024-1

ASVspoof5:CrowdsourcedSpeechData,Deepfakes,andAdversarialAttacksatScaleXinWang,H´ectorDelgado,HemlataTak,Jee-weonJung,Hye-jinShim,MassimilianoTodisco,IvanKukanov,XuechenLiu,MdSahidullah,TomiKinnunen,NicholasEvans,KongAikLee,JunichiYamagishiASVspoofconsortiumhttp://www.asvspoof.org/AbstractASVspoof5isthefiftheditioninaseriesofchallengeswhichpromotethestudyofspeechspoofinganddeepfakeat-tacks,andthedesignofdetectionsolutions.Comparedtopre-viouschallenges,theASVspoof5databaseisbuiltfromcrowd-sourceddatacollectedfromavastlygreaternumberofspeakersindiverseacousticconditions.Attacks,alsocrowdsourced,aregeneratedandtestedusingsurrogatedetectionmodels,whileadversarialattacksareincorporatedforthefirsttime.Newmet-ricssupporttheevaluationofspoofing-robustautomaticspeakerverification(SASV)aswellasstand-alonedetectionsolutions,i.e.,countermeasureswithoutASV.Wedescribethetwochal-lengetracks,thenewdatabase,theevaluationmetrics,base-lines,andtheevaluationplatform,andpresentasummaryoftheresults.Attackssignificantlycompromisethebaselinesys-tems,whilesubmissionsbringsubstantialimprovements.1.IntroductionTheASVspoofinitiativewasconceivedtofosterprogressinthedevelopmentofdetectionsolutions,alsoreferredtoascounter-measures(CMs)andpresentationattackdetection(PAD)solu-tions,todiscriminatebetweenbonafideandspoofedordeep-fakespeechutterances.ASVspoof5isthefiftheditioninaseriesofpreviously-biennialchallenges[1–4]andhasevolvedintermsofevaluationtracks,thedatabaseandspoofingattacks,andevaluationmetrics.Whilethe2021challengeeditioninvolveddistinctlogicalaccess(LA),physicalaccess(PA),andspeechdeepfake(DF)sub-tasks[5],ASVspoof5takestheformofasingle,com-binedLAandDFtask,butencompassestwotracks:(i)stand-alonespoofingandspeechdeepfakedetection(CM,noASV)and(ii)spoofing-robustautomaticspeakerverification(SASV).Track1issimilartotheDFtrackoftheprevious2021chal-lenge.Itreflectsascenarioinwhichanattackerhasaccesstothevoicedataofatargetedvictim,e.g.datapostedtosocialmedia.Theattackerisassumedtousepublicdataandspeechdeepfaketechnologytogeneratespoofedspeechresemblingthevoiceofthevictimandthen,e.g.,tore-postgeneratedrecord-ingstosocialmediatodefamethevictim.Speechdata,bothbonafideandspoofed,maybecompressedusingconventionalcodecs(e.g.,mp3)orcontemporaryneuralcodecs.Track2sharesthesamegoalastheLAsub-taskofpre-viousASVspoofeditionsandtheSASV2022Challenge[6].Track2assumesatelephonyscenariowheresyntheticandcon-vertedspeechareinjectedintoacommunicationsystem(e.g.,atelephoneline)withoutanyacousticpropagation.Participantscanelecttodevelopsingleclassifiersorseparate,fusedASVandCMsub-systems.Theycanuseeitherapre-trainedASVsub-systemprovidedbytheorganisersorcanoptimisetheirownbespokesystem.ParticipantsarefurthermoreprovidedwithanentirelynewASVspoof5database.Sourcedataandattacks,bothcrowdsourced,encompassgreateracousticvariationthanear-lierASVspoofdatabases.Theobjectiveistoevaluatethethreatofspoofinganddeepfakeattacksforgedusingnon-studio-qualitydataandoptimisedtocompromisenotjustASVsub-systemsbutalsoCMsub-systems.Sourcedata,collectedfromavastlygreaternumberofspeakersthanforearlierASVspoofdatabases,isextractedfromtheMultilingualLib-rispeech(MLS)Englishpartition[7].Inadditiontotheuseofnewspoofingattacksimplementedusingthelatesttext-to-speech(TTS)synthesisandvoiceconversion(VC)algorithms,adversarialattacksareintroducedforthefirsttimeandcom-binedwithspoofingattacks.AlsonewisanopenconditionforbothTracks1and2.Incontrasttothetraditionalclosedcondition,forwhichpartici-pantsarerestrictedtousethespecifieddataprotocol,fortheopenconditionparticipantshavetheopportunitytouseexter-naldataandpre-trainedspeechfoundationmodels,subjecttotherebeingnooverlapbetweentrainingdata(i.e.thatusedfortrainingfoundationmodels)andchallengeevaluationdata.Anewsuiteofevaluationmetricsisalsointroduced.In-spiredbytheNISTSREs[8],weadopttheminimumdetec-tioncostfunction(minDCF)astheprimarymetricforTrack1.Thelog-likelihood-ratiocostfunction(Cllr)andactualDCFarealsousedtogaugenotonlydiscriminationbutalsocalibrationperformance.Therecentlyproposedarchitecture-agnosticDCF(a-DCF)[9]isusedastheprimarymetricforTrack2,withthetandemdetectioncostfunction(t-DCF)[10]andtandemequalerrorrate(t-EER)[11]beingcomplementary.Wepresentanoverviewofthedatabase,thetwochallengetracks,commonsystemsandbaselines,andtheevaluationmet-rics.SpoofinganddeepfakeattacksandtheirperformanceinfoolinganASVsystemarealsodescribed.Finally,wereportasummaryofsystemperformanceforthebaselinesandthosesubmittedby54challengeparticipants.2.DatabaseThenewASVspoof5databasehasevolvedintwoaspects:sourcedataandattackalgorithms.ToevaluatetheperformanceofCMandSASVsystemsindetectingspoofingattacksforgedusingnon-studio-qualitydata,thenewdatabaseisconstructedusingdatasourcedfromtheMLSEnglishdataset[7].Thelatterincorporatesdatafrommorethan4kspeakers,recorded
2

Table1:SummaryofASVspoof5databasekeystatistics.Thenumberoftargetspeakersislistedinbraces.TargetspeakersrelatetoTrack2(T2)onlyandarenotdefinedforTrack1(T1).Figuresdonotincludeenrollmentutterances.#.speaker#.utterances#.spf.FemaleMaleBonafideSpoofedattackTrn.19620418,797163,5608Dev.392(196)393(202)31,334109,6168Eva.T1370367138,688542,08616Eva.T2370(194)367(173)100,708395,92416withdiversedevices.Thisisincontrasttothesourcedatabase(VCTK[12])ofpreviouschallenges,whichcontainsdatacol-lectedfrom100speakersinahemi-anechoicchamber.Thesecondmajorevolutionistheuseofstrongerspoof-ingattacks.InadditiontousingthelatestTTSandVCalgo-rithms,spoofingattacksaretunedtofoolnotonlyASV,butalsoCMsurrogatesub-systems.Thisisakeydifferencetopre-viousASVspoofdatabaseswhichwereconstructedbyverify-ingthatspoofingattackdataweresuccessfulinmanipulatinganASVsub-systemonly.Adversarialattacks,appliedtoaugmentthethreatofspoofingattacks,werecreatedusingMalafide[13]andMalacopula[14]filtering.TheformeraimstocompromisetheperformanceofCMs,whilethelatterescalatesthethreatofspoofeddatatoASV.Last,codecs,includingneural-network-basedvariants,areappliedtobothbonafideandspoofeddata.Thedatabasewasconstructedinthreestepswiththehelpoftwogroupsofdatacontributors.First,theMLSEnglishdatasetwasdividedintothreedisjointpartitions:A,B,andC.DatacontributorsinthefirstgroupusedpartitionAtobuildTTSsystems.WeusedtheresultingdatatotrainsurrogateASVandCMsystems(describedinSection4).DatacontributorsofthesecondgroupthenusedpartitionBtobuildnewTTSandVCsystems.ThelatteraretunedwiththeuseofsurrogateCMandASVsystemstoproduceclonedvoiceswhichsuccess-fullyfoolbothsub-systems.Finally,tunedTTSandVCsystemswereusedtoclonethevoicesoftargetspeakersinpartitionC.AsubsetofTTSandVCsystemswerefurthercombinedwithMalafideandMalacopulafiltering.Notethat,toavoidpotentialdataleakage,spoofingattacksandsurrogatesystemswerebuiltwithprivilegedprotocolswhichwerenotsharedwithchallengeparticipants.BonafidedatainthetrainingsetissourcedfromspeakersinpartitionA,whereasspoofeddataisgeneratedusingTTSsys-temsbuiltbythefirstgroupofdatacontributors.Bonafidedatainthedevelopmentandevaluationsetsaresourcedfromparti-tionC,whereasspoofeddataiscreatedbythesecondgroupofdatacontributors.ThespeakersintheASVspoof5challengetraining,development,andevaluationsetsaredisjoint.Asum-maryofkeystatisticsisshowninTable1.1Thespoofingattacksintraining,development,andevalu-ationsetsarealsodisjoint.AbriefsummaryofeachattackisshowninTable2.InadditiontolegacyTTSandVCalgo-rithms(e.g.,MaryTTS[16]),ASVspoof5spoofingattacksweregeneratedusingthelatestDNN-basedmethods(e.g.,ZMM-TTS[17]).Twopre-trainedsystems,namelyYourTTS[18]and1TheMLSEnglishdatasetisderivedfromthesamesourceasLib-rispeech[15].Becausechallengeparticipantsintheopenconditionwerepermittedtousemodelspre-trainedusingLibrispeech,were-movedalldatacollectedfromspeakersappearingintheevaluationsetwhentheyalsoappearinLibrispeech.Table2:Summaryofspoofingattacks.A01-A08,A09-A16,andA17-A32areintraining,development,andevaluationsets,respectively.ATdenotesadversarialattackusingMalafide,Malacopula,orboth.IDTypeAlgorithmIDTypeAlgorithmA01TTSGlowTTS[20]A17TTSZMM-TTS[17]A02TTSvariantofA01A18ATA17+MalafideA03TTSvariantofA01A19TTSMaryTTS[16]A04TTSGradTTS[21]A20ATA12+MalafideA05TTSvariantofA04A21TTSA09+BigVGAN[22]A06TTSvariantofA04A22TTSvariantofA09[23]A07TTSFastPitch[24]A23ATA09+MalafideA08TTSVITS[25]A24VCIn-houseASR-basedA09TTSToucanTTS[26]A25VCDiffVC[27]A10TTSA09+HifiGANv2[28]A26VCA16+originalgenuinenoiseA11TTSTacotron2[29]A27ATA26+MalacopulaA12TTSIn-houseunit-selectA28TTSPre-trainedYourTTS[18]A13VCStarGANv2-VC[30]A29TTSPre-trainedXTTS[19]A14TTSYourTTS[18]A30ATA18+Malafide+MalacopulaA15VCVAE-GAN[31]A31ATA22+MalacopulaA16VCIn-houseASR-basedA32ATA25+MalacopulaTable3:Summaryofcodecandcompressionconditionsineval-uationsetsofTrack1(☆)andTrack2(★).CodecBandwidthBitraterangeUsageC00-16kHz-☆★C01opus16kHz6.0-30.0☆★C02amr16kHz6.6-23.05☆★C03speex16kHz5.75-34.20☆★C04Encodec[32]16kHz1.5-24.0☆C05mp316kHz45-256☆C06m4a16kHz16-128☆C07mp3+Encodec16kHzvaried☆C08opus8kHz4.0-20.0☆★C09amr8kHz4.75-12.20☆★C10speex8kHz3.95-24.60☆★C11varied8kHzvaried☆★XTTS[19],werealsousedforthecloningoftargetspeakervoicesinazero-shotmanner.ToevaluatetheperformanceofCMandSASVsystemswhenbothbonafideandspoofeddataare(lossy)encodedorcompressed,evaluationdatawastreatedwiththesetofcodecslistedinTable3.ForconditionC00,thereisnoencodingorcompression.Forallotherconditions,bonafideandspoofedutterancesweretreatedwithoneofthecodecsC01-C11.C01-C07operatewitha16kHzsamplingrate,whileC08-C11oper-ateinan8kHznarrowbandsetting.Tocreatenarrowbanddata,bonafideandspoofeddataweredown-sampledto8kHz,pro-cessedwiththecodec,andthenup-sampledto16kHz.AlldataaresavedinFLACformatwithasamplingrateof16kHz.Forallutterancesintheevaluationdata,leadingandtrailingnon-speechsegmentsintheevaluationsetutteranceswereremoved.Participantsintheclosedconditionofbothtrackswerere-quiredtobuildtheirsystemsusingdatainthetrainingandde-velopmentsetsonly.Forbothtracks,participantsintheopenconditionwerepermittedtouseexternaltrainingdata,butonlyundertheconditionthatthereisnooverlapwiththechallengedatabase.Theuseofpre-trainedspeechfoundationmodelsbuiltusingaselectionofpubliclyavailabledatabases[33,§4.2]wasallowed.Theevaluationsetsforbothtrackscomprisethesamesetofutterances,exceptthatforthefourcodecconditionshigh-lightedinTable3whichwereexcludedinTrack2.
3

3.PerformancemeasuresThissectionprovidesabriefsummaryoftheperformancemea-suresusedinthetwochallengetracks.3.1.Track1:fromEERtoDCFSystemssubmittedtoTrack1wererequriedtoassignareal-valuedbonafide-spoofdetectionscoretoeachutterance.Dif-ferenttopastASVspoofeditionsforwhichtheEERwasusedastheprimarymetric,ASVspoof5adoptsthenormalizeddetec-tioncostfunction(DCF)[8]forTrack1.Whilefurtherdetailsareavailablein[33,Appendix],theDCFhasthesimpleformDCF(τcm)=β⋅Pcmmiss(τcm)+Pcmfa(τcm),(1)wherePcmmiss(τcm)isthemissrate(falserejectionrateforbonafideutterances)andPcmfa(τcm)isthefalsealarmrate(falseac-ceptancerateforspoofedutterances).Botharefunctionsofadetectionthreshold,τcm,andtheconstantβin(1)isdefinedasβ=CmissCfa⋅1−πspfπspf,(2)whereCmissandCfaare,respectively,thecostsofmissesandfalsealarms,andwhereπspfistheassertedpriorprobabilityofspoofingattacks.2ForthescenarioenvisionedinTrack1weassumethat,comparedtospoofedutterances,bonafidespeechutterancesare,ingeneral,farmorelikelyinpractice(lowπspf).But,whenencounteredbutnotdetected,therelativecostishigh.WesetCmiss=1,Cfa=10,πspf=0.05,whichgivesβ≈1.90.ThenormalizedDCFin(1)isusedtocomputebothmin-imumandactualDCFs.TheformeristheprimarymetricforTrack1,definedasminDCF=minτcmDCF(τcm).Thelat-ter,actDCF=DCF(τBayes),istheDCFevaluatedatafixedthresholdτBayes=−log(β)undertheassumptionthatdetec-tionscorescanbeinterpretedaslog-likelihoodratios(LLRs).WhereastheminDCFmeasuresperformanceusingan‘oracle’threshold(setbasedonground-truth),theactDCFmeasurestherealisedcostobtainedbysettingthethresholdtoτBayes[8].NotethatthisismeaningfulonlywhenscorescanbeinterpretedascalibratedLLRs[34,35].Similartopastchallengeeditions,thesubmissionofLLRscoreswasnotrequired—rather,itwasen-couragedforthefirsttime.3Anothercomplementarymetric,thecostoflog-likelihoodratios(Cllr)[34],wasusedtoassessthequalityofdetectionscoreswheninterpretedasLLRsCllr=12log2(1∣B∣∑si∈Blog(1+e−si)+1∣S∣∑sj∈Slog(1+esj)),(3)whereB={si}andS={sj}denote,respectively,thesetsofbonafideandspoofedtrialscores.ThelowerCllr,thebettercalibrated(andmorediscriminative)thescores.InadditiontominDCF,actDCF,andCllr,theEERisalsoreported.3.2.Track2:fromSASV-EERtoa-DCFForTrack2,participantscouldsubmiteithersinglereal-valuedSASVscoresoratripletofscoreswhich,inadditiontoSASV2Sincewehaveonlytwoclasses,itfollowsthat1−πspfistheas-sertedpriorofthebonafideclass.3Rawdetectionscorescanbepost-processedintoLLRsusingim-plementationssuchas[35]inordertoreduceactDCF.Note,however,thatanyorder-preservingscorecalibrationdoesnotaffecttheprimaryminDCFmetric.scores,containsspoofing(CMsub-system)andspeaker(ASVsub-system)detectionscores.Whiletheformercanbepro-ducedbyanymodelarchitecturewhichoutputsasingledetec-tionscore,thelatterassumesaspecifictandem(cascade)archi-tecture[10]consistingoftwoclearly-identifiedCMandASVsub-systems.Inthiscase,SASVscoresaregeneratedbycom-biningsub-systemsoutputs(e.g.,embeddingsorscores)usinganarbitrarycombinationstrategydesignedbytheparticipants.Forbothtypesofsubmission,SASVscoresareusedtocomputetheprimarychallengemetric.Track2takesastepforwardfromEER-basedmetricsusedinthefirstSASVchal-lenge[6]toDCF-basedmetrics.Buildinguponthetwo-classDCF(1),anormalizedarchitecture-agnosticdetectioncostfunction(a-DCF)[9]wasrecentlyproposedandisdefinedasa-DCF(τsasv)=αPsasvmiss(τsasv)+(1−γ)Psasvfa,non(τsasv)+γPsasvfa,spf(τsasv),(4)wherePsasvmiss(τsasv)istheASVmiss(targetspeakerfalserejec-tion)rateandwherePsasvfa,non(τsasv)andPsasvfa,spf(τsasv)arethefalsealarm(falseacceptance)ratesfornon-targetsandspoofingat-tacks,respectively.AllthreeerrorratesarefunctionsofanSASVthresholdτsasv.Theconstantsαandγaregivenbyα=CmissπtarCfa,nonπnon+Cfa,spfπspf,γ=Cfa,spfπspfCfa,nonπnon+Cfa,spfπspf,(5)whereCmiss,Cfa,non,andCfa,spoofarethecostsofamiss,thefalseacceptanceofanon-targetspeaker,andthefalseaccep-tanceofaspoofingattack,andwhereπtar,πnon,andπspoofaretheassertedpriorsoftargets,non-targets(zero-effortimpostors),andspoofingattacks.TheassumptionsaresimilartothoseforTrack1.Wesetπtar=0.9405,πnon=0.0095,πspf=0.05,Cmiss=1andCfa,non=Cfa,spf=10.Thisgivesα≈1.58andγ≈0.84.TheprimarymetricforTrack2istheminimuma-DCF,mina-DCF=minτsasva-DCF(τsasv).Forsubmissionswhichprovideclearly-identifiedASVandCMsub-systems,theASV-constrainedminimumtandemdetec-tioncostfunction(t-DCF)[10]andthetandemequalerrorrate(t-EER)[11]arealsoreported.WhereastheformerhasservedastheprimarymetricsinceASVspoof2019,thelatterprovidesacomplementaryparameter-freemeasureofclassdis-crimination.Thet-DCFmetriciscomputedusingthesamecostsandpriorsasaboveandusingASVscoresproducedbyacommonASVsystem(seeSection4)inplaceofscorespro-videdtheparticipant.Thisallowscomputationoftheminimum‘ASV-constrained’t-DCFinthesamewayasforthepreviousASVspoofchallengesandenablesthecomparisonofdifferentCMsub-systemswhentheyarecombinedwithacommonASVsub-system.Forcomputationofthet-EERmetric,boththeCMandASVsub-systemscoresareusedtoobtainasingleconcurrentt-EERvalue,denotedbyt-EER×.IthasasimpleinterpretationastheerrorrateatauniquepairofASVandCMthresholds,τ×∶=(τ×asv,τ×cm),atwhichthemissrateandthetwotypesoffalsealarmrates(oneforspoofingattacks,theotherfornon-targets)areequal:t-EER×=Ptdmmiss(τ×)=Ptdmfa,non(τ×)=Ptdmfa,spoof(τ×).Thesuperscript‘tdm’isusedtoemphasizetheassumedtandemarchitecture.Thet-EERcanbeseenasageneralisationoftheconventionaltwo-class,singlesystemEERwhichprovidesanapplication-agnosticdiscriminationmeasure.
4

BonaﬁdeA17A18A19A20A21A22A23A24A25A26A27A28A29A30A31A32Allattacks01020304050ASVEER(%)Figure1:ASVEERsforthecommonASVsystemandevalua-tiondata.Resultsarepooledoverthesetofcodecconditions.4.CommonASV,baselineandsurrogatesystems4.1.CommonASVsystemThecommonASVsystemusesanECAPA-TDNNspeakeren-coder[36]andcosinesimilarityscoring.TheECAPA-TDNNmodelistrainedusingthetrainingpartitionsoftheVoxCeleb1and2databases[37].Cosinescoresaresubsequentlynor-malisedusings-norm.Figure1illustratesASVEERsfortheevaluationdata.Whendiscriminatingbetweenbonafidetargetandnon-targetdata(leftmostbar),theEERis5%.However,theEERsaremuchhigherwhenbonafidenon-targetdataisreplacedwithspoofingattacks.Notethat,althoughA25istheleasteffectiveattack,itprovesmorethreateningwhenenhancedintheformofanadversarialattackA32.4.2.BaselinesystemsForTrack1therearetwoCMbaselinesystems:RawNet2[38](B01)andAASIST[39](B02).Bothsystemsareend-to-end,operatingdirectlyonrawwaveformsof4secondsduration(64,000samples).RawNet2iscomposedofafixedbankof20sincfiltersandsixresidualblocksfollowedbygatedrecurrentunits,whichconvertframe-levelrepresentationstoutterance-levelrepresentations.Outputscoresaregeneratedusingfully-connectedlayers.AASISTusesaRawNet2-basedencoder[38]toextractspectro-temporalfeaturesfromtheinputwaveform.Aspectro-temporalheterogeneousgraphattentionlayersandmaxgraphoperationsarethenusedtointegratetemporalandspectralrepresentations.CMoutputscoresaregeneratedusingareadoutoperationandalinearoutputlayer.Bothbaselinesweretrainedwithaweightedcross-entropylossforbinaryclas-sification.TherearetwobaselinesforTrack2:afusion-basedsys-tem[6](B03)andasingleintegratedsystem[40](B04).B03,adoptedfromtheSASV2022challengebaseline,isafusionofthecommonASVsystemandtheTrack1AASISTbaseline,usinganLLR-basedfusiontool[41].B04,whichisbasedonMFA-Conformer[42],extractsasingleembeddingfromthein-putwaveformandproducesasingleSASVscore.Itistrainedinthreestages:speakerclassification-basedpre-training,copysynthesistraining[43]withadaptedSASVlossfunctions,andin-domainfine-tuning.VoxCelebandcopysynthesisdataareusedinthefirstandsecondstages,respectively.In-domainfine-tuningisconductedusingASVspoof5trainingdata.SourcecodesforallbaselinesareaccessiblefromtheASVspoof5Githubrepository.44github.com/asvspoof-challenge/asvspoof5050100150200250#submissionsTrack1ClosedconditionOpencondition0510152025Days0204060#submissionsTrack2Figure2:AstackedbarchartshowingthenumberofCodaLabsubmissionstoTracks1and2forthe26-dayprogressand3-dayevaluationphases.4.3.SurrogatesystemsThesurrogateASVsystemisbasedonECAPA-TDNNandaprobabilisticlineardiscriminantanalysisscoringbackend[44].SurrogateCMsystemsincludeAASIST,RawNet2,andLCNNswithLFCCfeatures,allofwhicharetrainedusingbonafidedatainMLSpartitionAandspoofingattackscreatedbythefirstgroupofdatacontributors(seeSection2),i.e.withoutattackscontainedineitherthedevelopmentorevaluationsets.5.EvaluationplatformASVspoof5usedtheCodaLabwebsitethroughwhichpartic-ipantscouldsubmitdetectionscoresandreceiveresults.Thechallengewasrunintwophases(withanadditionalpost-evaluationphasenotaddressedinthispaper).Duringthefirst26-dayprogressphase,participantscouldmakeuptofoursub-missionsperday.Resultsderivedfromanevaluationsubset(theprogresssubset)weremadeavailabletoparticipantswhocouldthenopttosubmittheirresultstoananonymisedleader-board.Theevaluationphaseranforonlyafewdays,duringwhichparticipantscouldmakeonlyasinglesubmission.Eval-uationsubmissionswereevaluatedusingthewholeevaluationset.Figure2illustratesthenumberofsubmissionsduringtheprogressandevaluationphases.ForTrack1,therewereacom-parablenumberofsubmissionstoclosedandopenconditions.Incontrast,forTrack2,thenumberofsubmissionstotheopenconditionoutstrippedthosetotheclosedcondition,possiblyanindicationoftheneedforadditionaldatatosupportthetrainingofSASVsystems.6.Challengeresults6.1.Track1ResultsforTrack1arelistedinTable4.ThebaselinesystemsachieveminDCFsnolowerthan0.7andEERsnolowerthan29%.EvenifRawNet2andAASISTbothachievepromisingresultsinthecaseofpreviousASVspoofchallengedatabases,resultsfortheASVspoof5databasearefarworse,andarelikelycausedbytheuseofnon-studio-qualitysourcedataaswellas
5

Table4:Track1evaluationresults.Ensemblesystemsandsinglesystemsaremarkedby•and◦,respectively.Open-conditionsubmissionsusingandnotusingpre-trainedself-supervisedmodelsaremarkedby▲and△,respectively.TheabsenceofaTeamIDindicatessubmissionsforwhichasystemdescriptionwasnotreceived.Submissionsmadeaftertheinitialdeadlineareunderscored.Closedcondition#IDminDCFactDCFCllrEER#IDminDCFactDCFCllrEER•1T320.24360.99560.94588.6118-0.59900.96666.631324.12•2T470.26600.33800.60919.1819-0.60860.60910.826528.65•3T240.29750.29760.418210.43•20T070.62851.00001.075225.47•4T450.39481.00000.851514.33•21T270.63391.09371.080826.17•5T130.40250.42180.523814.7522-0.64630.83882.325126.456-0.40790.42990.551214.16•23T410.65430.76410.918426.287-0.43900.63320.853117.09◦24T060.65981.00001.115928.41•8T460.47831.00001.050920.4525-0.66170.98940.956227.31•9T230.53121.00001.117120.13◦26T140.66180.93072.485825.3210-0.53401.00001.022819.1027-0.69890.70061.693531.1511-0.53570.95333.306922.67◦28B020.71060.92984.001429.12•12T350.55051.00001.143523.42◦29T440.79971.00001.277435.1513-0.58090.85374.099423.3430-0.81651.00001.123644.94◦14T480.58130.93543.192323.63◦31B010.82660.99224.093536.04◦15T190.58910.68831.327724.59•32T540.86241.00001.122139.6816-0.58951.00000.935123.93◦33T530.97441.05392.497744.9417-0.58990.74701.379822.58Opencondition#IDminDCFactDCFCllrEER#IDminDCFactDCFCllrEER•▲1T450.07501.00000.79232.5918-0.19490.24380.70287.05•▲2T360.09361.00000.88743.4119-0.19661.00000.93276.80•▲3T270.09370.13750.19273.42•▲20T330.20210.60280.55607.01•▲4T230.11241.00000.91794.1621-0.21481.00000.81247.43•▲5T430.11490.57290.95624.04•▲22T510.22361.00000.80117.72•▲6T130.13010.14150.37914.50•▲23T460.22451.00001.03089.36•▲7T060.13480.21700.30965.0224-0.25731.00000.99559.288-0.14140.52880.61494.8925-0.26420.70372.189210.32◦▲9T310.14990.22440.55595.56•△26T470.26600.33210.49329.18•▲10T290.15490.20520.72885.3727-0.26680.29230.61949.59•▲11T350.16111.00001.03845.93•▲28T410.30100.30950.477310.4512-0.16650.16690.23515.7729-0.41210.42660.718514.25•▲13T210.17280.23920.94986.01•▲30T020.48451.00000.933217.08◦▲14T170.17291.00002.32175.99◦△31T150.51120.67230.885822.24◦▲15T190.17430.30870.47576.0632-0.65840.74511.140422.9016-0.18401.00000.87646.3533-0.79691.00000.992035.7217-0.19331.00000.83426.67◦△34T530.97441.05392.497744.94moreadvancedspoofingandadversarialattacks.Encouragingly,mostsubmissionstotheclosedconditionoutperformthebaselinesintermsofminDCF.Thetop-5sub-missionsobtainminDCFsbelow0.5andEERsbelow15%,arelativeimprovementoverthebaselinesof∼50%.Similartothetrendobservedinpreviouschallengeeditions,submissionsusinganensembleofsub-systemstendtoperformbetter.Unsurprisingly,minDCFandEERvaluesfortheopencon-ditionarelowerthanthosefortheclosedcondition.Notably,mostofthetop-performingsubmissionsusefeaturesextractedusingpre-trained,self-supervisedlearning(SSL)models,e.g.,wav2vec2.0(baseversion)[45].Despitetheencouragingresults,thetopsystemsforbothconditionsobtainactDCFvaluescloseorequalto1.0.Thisisbecausesystemoutputsare‘normalized’tobetween0and1ratherthanbeingcalibratedtoapproximateLLRs.ScoresareabovetheoptimalBayesdecisionthresholdspecifiedbythepriorsanddecisioncosts,whichleadstoPcmmiss(τcm)=0,Pcmfa(τcm)=1,andactDCFequalto1.0.Cllrvaluesarealsohigh,againasignofpoorcalibration.Incontrast,somesystems,suchasT24undertheclosedcondition,arebettercal-ibrated.6.2.Track2ResultsforTrack2arelistedinTable5.ThedesignofSASVsolutionsisperhapsmoretechnicallydemandingthanthatofstand-aloneCMs.ThismightaccountforthelowernumberofsubmissionstoTrack2.PerformanceforB03isnotdissimi-lartothatofthereferencesystem(REF)whichisthesameasB03exceptfortheuseofaCMsub-systemwhichproducesrandomoutputs.guessingCMsub-system.ThisindicatesthattheCMsub-systemofB03doesnotprovideinformationwhich
6

Table5:Track2evaluationresults.SubmissionswithonlySASVscoresarenotevaluatedusingmint-DCFandt-EER.Submissionsusingasystemensembleandasinglesystemaremarkedby•and◦,respectively.Open-conditionsubmissionsusingandnotusingpre-trainedself-supervisedmodelsaremarkedby▲and△,respectively.TheabsenceofaTeamIDindicatessubmissionsforwhichasystemdescriptionwasnotreceived.Submissionsmadeafterthedeadlineareunderscored.REFdenotestheorganisers’ASV(§4)withoutaCM.Closedcondition#IDmina-DCFmint-DCFt-EER#IDmina-DCFmint-DCFt-EER•1T450.2814--•9T230.45130.827949.34•2T240.29540.61759.5810-0.5130--•3T470.31730.52617.49◦11B040.5741--4-0.3542--12-0.62090.907325.395-0.3744--◦13B030.68060.929528.786-0.38930.778320.85◦14REF0.6869--7-0.3896--15-0.8985--8-0.39710.700715.09Opencondition#IDmina-DCFmint-DCFt-EER#IDmina-DCFmint-DCFt-EER•▲1T450.0756--7-0.17970.54308.39•▲2T390.11560.45844.328-0.3896--•▲3T360.12030.42914.549-0.4581--•▲4T060.12950.43725.43◦△10REF0.6869--◦▲5T290.14100.46905.4811-0.9134--•▲6T230.14920.40754.63isusefultotherejectionofspoofingattacks.Thesingleinte-gratedB04baselineperformsbetter.However,theseresultsdonotshowthatfusion-basedsolutionsareinferior;allofthetop-performingsubmissionsarebaseduponthefusionofASVandCMsub-systems,includingT45.Mostsubmissionsoutperformthebaselines.Forthetop-3submissionstotheclosedcondition,theimprovementsare∼50%relativetothebestbaselineintermsofmina-DCF.Sim-ilartofindingsforTrack1,submissionstotheopenconditionachievebetterperformanceandtheuseofSSL-basedfeaturesiscommonamongthetop-performingsubmissions.7.ConclusionsWepresentanoutlineoftheASVspoof5challengewhichisdesignedtosupporttheevaluationofbothstand-alonespeechspoofinganddeepfakedetectionandSASVsolutions.Thefiftheditionwasconsiderablymorecomplexthanitspredecessors,andincludednotonlyanewtask,butalsomorechallengingcrowdsourceddatacollectedundervariableconditions,spoof-ingattacksgeneratedwithavarietyofcontemporaryalgorithmstunedtofoolsurrogateASVandCMsub-systems,andnewad-versarialattacks.Despitetheuseoflower-qualitydatatocreatespoofsanddeepfakes,detectionperformanceforthebaselinesystems,alltop-performingsystemsreportedinrecentyears,isrelativelypoor.Encouragingly,resultsformostchallengesub-missionsoutperformthechallengebaselines,sometimesbyasubstantialmargin.Resultsalsorevealthehithertoignoredis-sueofscorecalibration,anessentialconsiderationifdetectionsolutionsaredeployedinpracticalscenarios.Withaparticu-larlytightscheduleforASVspoof5,moredetailedanalyseswillbepresentedattheworkshopandreportedinfuturework.8.AcknowledgementsTheASVspoof5organisingcommitteeexpressesitsgratitudeandappreciationtothechallengeparticipants.Forreasonsofanonymity,theycouldnotbeidentifiedinthisarticle.Subjecttothepublicationoftheirresultsandpriorapproval,theywillbecitedorotherwiseacknowledgedinfuturework.TheASVspoof5organisingcommitteeextendsitssin-ceregratitudetodatacontributors(inalphabeticorder):ChengGong,TianjinUniversity;ChengzheSun,ShuweiHou,SiweiLyu,UniversityatBuffalo,StateUniversityofNewYork;Flo-rianLux,UniversityofStuttgart;GeZhu,NeilZhang,YongyiZang,UniversityofRochester;GuoHanjieandLipingChen,UniversityofScienceandTechnologyofChina;HengchengKuoandHung-yiLee,NationalTaiwanUniversity;MyeonghunJeong,SeoulNationalUniversity;NicolasMuller,FraunhoferAISEC;S´ebastienLeMaguer,UniversityofHelsinki;SoumiMaiti,CarnegieMellonUniversity;YihanWu,RenminUniver-sityofChina;YuTsao,AcademiaSinica;VishwanathPratapSingh,UniversityofEasternFinland;WangyouZhang,Shang-haiJiaotongUniversity.ThecommitteewouldliketoacknowledgeA⋆STAR(Sin-gapore)forsponsoringitsuseoftheCodaLabplatform,inad-ditiontoPindrop(USA)andKLASSEngineeringandSolu-tions(Singapore)forsponsoringtheASVspoof2024Work-shop.ThisworkisalsopartiallysupportedbyJST,PRESTOGrantNumberJPMJPR23P9,JapanandwithfundingreceivedfromtheFrenchAgenceNationaledelaRecherche(ANR)viatheBRUEL(ANR-22-CE39-0009)andCOMPROMIS(ANR-22-PECY-0011)projects.Thisworkwasalsopartiallysup-portedbytheAcademyofFinland(DecisionNo.349605,projectSPEECHFAKES).PartofthisworkusedtheTSUB-AME4.0supercomputeratTokyoInstituteofTechnology.
7

9.References[1]ZhizhengWu,TomiKinnunen,NicholasEvans,JunichiYamagishi,CemalHanilc¸i,Md.Sahidullah,andAlek-sandrSizov,“ASVspoof2015:thefirstautomaticspeakerverificationspoofingandcountermeasureschallenge,”inProc.Interspeech,2015,pp.2037–2041.[2]TomiKinnunen,Md.Sahidullah,HectorDelgado,Massi-milianoTodisco,NicholasEvans,JunichiYamagishi,andKong-AikLee,“TheASVspoof2017challenge:Assess-ingthelimitsofreplayspoofingattackdetection,”inProc.Interspeech,2017,pp.2–6.[3]MassimilianoTodisco,XinWang,VilleVestman,Md.Sahidullah,HectorDelgado,AndreasNautsch,JunichiYamagishi,NicholasEvans,TomiHKinnunen,andKongAikLee,“ASVspoof2019:futurehorizonsinspoofedandfakeaudiodetection,”inProc.Interspeech,2019,pp.1008–1012.[4]JunichiYamagishi,XinWang,MassimilianoTodisco,MdSahidullah,JosePatino,AndreasNautsch,XuechenLiu,KongAikLee,TomiKinnunen,NicholasEvans,andHectorDelgado,“ASVspoof2021:Acceleratingprogressinspoofedanddeepfakespeechdetection,”inProc.ASVspoofChallengeWorkshop,2021,pp.47–54.[5]XuechenLiu,XinWang,MdSahidullah,JosePatino,HectorDelgado,TomiKinnunen,MassimilianoTodisco,JunichiYamagishi,NicholasEvans,AndreasNautsch,andKongAikLee,“ASVspoof2021:TowardsSpoofedandDeepfakeSpeechDetectionintheWild,”IEEE/ACMTransactionsonAudio,Speech,andLanguageProcess-ing,vol.31,pp.2507–2522,2023.[6]Jee-weonJung,HemlataTak,Hye-jinShim,Hee-SooHeo,Bong-JinLee,Soo-WhanChung,Ha-JinYu,NicholasEvans,andTomiKinnunen,“SASV2022:TheFirstSpoofing-AwareSpeakerVerificationChallenge,”inProc.Interspeech,2022,pp.2893–2897.[7]VineelPratap,QiantongXu,AnuroopSriram,GabrielSynnaeve,andRonanCollobert,“MLS:ALarge-ScaleMultilingualDatasetforSpeechResearch,”inProc.In-terspeech,2020,pp.2757–2761.[8]NIST,NIST2020CTSSpeakerRecognitionChallengeE-valuationPlan,2020.[9]Hye-jinShim,Jee-weonJung,TomiKinnunen,etal.,“a-DCF:anarchitectureagnosticmetricwithapplicationtospoofing-robustspeakerverification,”inProc.SpeakerOdyssey,2024,pp.158–164.[10]TomiKinnunen,H´ectorDelgado,NicholasEvans,etal.,“Tandemassessmentofspoofingcountermeasuresandau-tomaticspeakerverification:Fundamentals,”IEEE/ACMTransactionsonAudio,Speech,andLanguageProcess-ing,vol.28,pp.2195–2210,2020.[11]TomiH.Kinnunen,KongAikLee,HemlataTak,etal.,“t-EER:Parameter-freetandemevaluationofcountermea-suresandbiometriccomparators,”IEEETransactionsonPatternAnalysisandMachineIntelligence,vol.46,no.5,pp.2622–2637,2024.[12]JunichiYamagishi,ChristopheVeaux,andKirstenMac-Donald,“CSTRVCTKCorpus:EnglishMulti-speakerCorpusforCSTRVoiceCloningToolkit(version0.92),”2019.[13]MichelePanariello,WanyingGe,HemlataTak,Massim-ilianoTodisco,andNicholasEvans,“Malafide:anoveladversarialconvolutivenoiseattackagainstdeepfakeandspoofingdetectionsystems,”inProc.Interspeech,2023,pp.2868–2872.[14]MassimilianoTodisco,MichelePanariello,XinWang,HectorDelgado,Kong-AikLee,andNicholasEvans,“Malacopula:Adversarialautomaticspeakerverificationattacksusinganeural-basedgeneralisedhammersteinmodel,”inProc.ASVspoofWorkshop2024,2024.[15]VassilPanayotov,GuoguoChen,DanielPovey,andSan-jeevKhudanpur,“Librispeech:AnASRcorpusbasedonpublicdomainaudiobooks,”inProc.ICASSP,2015,pp.5206–5210.[16]IngmarSteinerandS´ebastienLeMaguer,“Creatingnewlanguageandvoicecomponentsfortheupdatedmaryttstext-to-speechsynthesisplatform,”inProc.LREC,2018,pp.3171–3175.[17]ChengGong,XinWang,EricaCooper,DanWells,LongbiaoWang,JianwuDang,KorinRichmond,andJunichiYamagishi,“ZMM-TTS:Zero-shotmultilin-gualandmultispeakerspeechsynthesisconditionedonself-superviseddiscretespeechrepresentations,”arXivpreprintarXiv:2312.14398,2023.[18]EdressonCasanova,JulianWeber,ChristopherDShulby,ArnaldoCandidoJunior,ErenG¨olge,andMoacirAPonti,“Yourtts:Towardszero-shotmulti-speakerTTSandzero-shotvoiceconversionforeveryone,”inProc.ICML,2022,pp.2709–2720.[19]EdressonCasanova,KellyDavis,ErenG¨olge,G¨orkemG¨oknar,IulianGulea,LoganHart,AyaAljafari,JoshuaMeyer,ReubenMorais,SamuelOlayemi,etal.,“XTTS:Amassivelymultilingualzero-shottext-to-speechmodel,”Proc.Interspeech,2024.[20]JaehyeonKim,SungwonKim,JungilKong,andSungrohYoon,“Glow-TTS:Agenerativeflowfortext-to-speechviamonotonicalignmentsearch,”inProc.NeurIPS,2020,vol.33,pp.8067–8077.[21]VadimPopov,IvanVovk,VladimirGogoryan,TasnimaSadekova,andMikhailKudinov,“Grad-TTS:Adiffusionprobabilisticmodelfortext-to-speech,”inProc.ICML,2021,pp.8599–8608.[22]Sang-gilLee,WeiPing,BorisGinsburg,BryanCatan-zaro,andSungrohYoon,“BigVGAN:Auniversalneuralvocoderwithlarge-scaletraining,”inProc.ICLR,2022.[23]FlorianLux,JuliaKoch,andNgocThangVu,“Ex-actProsodyCloninginZero-ShotMultispeakerText-to-Speech,”inProc.SLT,2023,pp.962–969.[24]AdrianŁa´ncucki,“Fastpitch:Paralleltext-to-speechwithpitchprediction,”inProc.ICASSP,2021,pp.6588–6592.[25]JaehyeonKim,JungilKong,andJuheeSon,“Conditionalvariationalautoencoderwithadversariallearningforend-to-endtext-to-speech,”inProc.ICML,2021,pp.5530–5540.[26]FlorianLux,JuliaKoch,andNgocThangVu,“Low-resourcemultilingualandzero-shotmultispeakerTTS,”inProc.AACL,2022,pp.741–751.
8

[27]VadimPopov,IvanVovk,VladimirGogoryan,Tas-nimaSadekova,MikhailKudinov,andJianshengWei,“Diffusion-basedvoiceconversionwithfastmaximumlikelihoodsamplingscheme,”inProc.ICLR,2022.[28]JungilKong,JaehyeonKim,andJaekyoungBae,“HiFi-GAN:Generativeadversarialnetworksforefficientandhighfidelityspeechsynthesis,”inProc.NeurIPS,2020,vol.33,pp.17022–17033.[29]JonathanShen,RuomingPang,RonJWeiss,MikeSchuster,NavdeepJaitly,ZonghengYang,ZhifengChen,YuZhang,YuxuanWang,RjSkerrv-Ryan,etal.,“Natu-ralTTSsynthesisbyconditioningwavenetonMelspec-trogrampredictions,”inProc.ICASSP,2018,pp.4779–4783.[30]YinghaoAaronLi,AliZare,andNimaMesgarani,“StarGANv2-VC:Adiverse,unsupervised,non-parallelframeworkfornatural-soundingvoiceconversion,”inProc.Interspeech,2021,pp.1349–1353.[31]EhabA.AlBadawyandSiweiLyu,“VoiceConversionUsingSpeech-to-SpeechNeuro-StyleTransfer,”inProc.Interspeech,2020,pp.4726–4730.[32]AlexandreD´efossez,JadeCopet,GabrielSynnaeve,andYossiAdi,“Highfidelityneuralaudiocompression,”TransactionsonMachineLearningResearch,2023,Fea-turedCertification,ReproducibilityCertification.[33]HectorDelgado,NicholasEvans,Jee-weonJung,TomiKinnunen,IvanKukanov,Kong-AikLee,XuechenLiu,Hye-jinShim,MdSahidullah,Hem-lataTak,MassimilianoTodisco,XinWang,andJunichiYamagishi,“ASVspoof5evaluationplan(phase2),”https://www.asvspoof.org/file/ASVspoof5___Evaluation_Plan_Phase2.pdf,v0.6,accessed23-July-2024.[34]NikoBr¨ummerandJohanduPreez,“Application-independentevaluationofspeakerdetection,”ComputerSpeech&Language,vol.20,no.2,pp.230–275,2006.[35]LucianaFerrer,“Calibrationtutorial,”https://github.com/luferrer/CalibrationTutorial,2024.[36]BrechtDesplanques,JentheThienpondt,andKrisDe-muynck,“ECAPA-TDNN:EmphasizedChannelAt-tention,PropagationandAggregationinTDNNBasedSpeakerVerification,”inProc.Interspeech,2020,pp.3830–3834.[37]ArshaNagrani,JoonSonChung,andAndrewZisser-man,“VoxCeleb:ALarge-ScaleSpeakerIdentificationDataset,”inProc.Interspeech,2017,pp.2616–2620.[38]HemlataTak,JosePatino,MassimilianoTodisco,AndreasNautsch,NicholasEvans,andAnthonyLarcher,“End-to-endanti-spoofingwithRawNet2,”inProc.ICASSP.IEEE,2021,pp.6369–6373.[39]Jee-weonJung,Hee-SooHeo,HemlataTak,Hye-jinShim,JoonSonChung,Bong-JinLee,Ha-JinYu,andNicholasEvans,“AASIST:Audioanti-spoofingusingin-tegratedspectro-temporalgraphattentionnetworks,”inProc.ICASSP,2022,pp.6367–6371.[40]SungHwanMun,Hye-jinShim,HemlataTak,XinWang,XuechenLiu,MdSahidullah,MyeonghunJeong,MinHyunHan,MassimilianoTodisco,KongAikLee,etal.,“Towardssingleintegratedspoofing-awarespeakerverificationembeddings,”inProc.Interspeech,2023,pp.3989–3993.[41]XinWang,TomiKinnunen,LeeKongAik,Paul-GauthierNoe,andJunichiYamagishi,“Revisitingandimprovingscoringfusionforspoofing-awarespeakerverificationus-ingcompositionaldataanalysis,”inProc.Interspeech,2024.[42]YangZhang,ZhiqiangLv,HaibinWu,ShanshanZhang,PengfeiHu,ZhiyongWu,Hung-yiLee,andHelenMeng,“MFA-conformer:Multi-scalefeatureaggregationcon-formerforautomaticspeakerverification,”inProc.In-terspeech,2022,pp.306–310.[43]XinWangandJunichiYamagishi,“Spoofedtrainingdataforspeechspoofingcountermeasurecanbeefficientlycre-atedusingneuralvocoders,”inProc.ICASSP,2023.[44]SimonJDPrinceandJamesHElder,“Probabilisticlin-eardiscriminantanalysisforinferencesaboutidentity,”inProc.ICCV,2007,pp.1–8.[45]AlexeiBaevski,YuhaoZhou,AbdelrahmanMohamed,andMichaelAuli,“Wav2vec2.0:Aframeworkforself-supervisedlearningofspeechrepresentations,”inProc.NuerIPS,2020,vol.33,pp.12449–12460.