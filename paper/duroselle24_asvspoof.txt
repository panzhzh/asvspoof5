The Automatic Speaker Verification Spoofing Countermeasures Workshop (ASVspoof 2024)
31 August 2024, Kos, Greece

16

10.21437/ASVspoof.2024-3

DataaugmentationsforaudiodeepfakedetectionfortheASVspoof5closedconditionRapha¨elDuroselle¹,OlivierBoeffard¹,AdrienCourtois¹,HubertNourtel²,PierreChampion¹,HeikoAgnoli¹,Jean-Franc¸oisBonastre¹¹InriaD´efenseetS´ecurit´e/LR2,²StoryzyFrancefirstname.name@inria.fr,firstname.name@storyzy.comAbstractThispaperdescribesthejointparticipationofInriaD´efenseetS´ecurit´eandStoryzytotheASVspoof5challenge.Wepartic-ipatedintheclosedconditionsoftheaudiodeepfakedetectionandofthespoofing-awarespeakerverificationtrackswiththegoalofevaluatingtheperformanceofcountermeasureswithafixedsetoftrainingattacks.Theproposedcountermeasuresystemisthecombinationofthreemodelswithdifferentarchi-tecturesandtrainingalgorithms,includingtheexplorationofaself-supervisedlearningpretrainingapproach.Specificdataaugmentationstrategiesareintroducedtoincreaserobustnesstodatatransmissionandgeneralizationtounknownattacks.ThesubmittedsystemachievesaminDCFof0.297fortrack1andamina-DCFof0.295fortrack2.Ithasaverysmallcalibra-tionerror(actDCFof0.298)despitethepresenceofunknowncodecsandadversarialattackswithintheevaluationcorpus.1.IntroductionTheASVspoofseriesofchallenges[1]fostersthedevelopmentofaudiodeepfakedetectionsystems.Thepoorgeneralizationofcurrentcountermeasurestoin-the-wilddata[2]highlightstheneedformorerealisticdatasets.TheASVspoof2021edi-tionmarkedasignificantadvancementtowardssimulatingmorerealisticscenarios,includingtheuseoflow-qualityrecordingsandcodeccompression[3].InthelatestASVspoof5edition,thechallengehasbeenelevatedfurtherbyintroducingmoredemandingconditions,suchascrowdsourcedadversarialat-tacks[4].Themainobjectiveofanaudiodeepfakedetectiontaskisageneralisedcountermeasure,thatisspoofingdetectionsolu-tionswhichperformreliablyinthefaceofutterancesgeneratedwithneworpreviouslyunseenspoofingattackalgorithmsandmethods[1].Wetookpartinthetwotracksoftheclosedcon-dition(audiodeepfakedetectionandspoofing-awareautomaticspeakerverification)inordertoevaluatethegeneralizationofdifferentmodelswithafixedgapbetweenthetrainingandeval-uationattacks,independentlyoftheproblemofcollectingarep-resentativedatasetofexistingattacks.1.1.MotivationAnidealdeepfakedetectionsystemwouldprocessasananomalydetectionmechanism,broadlyapplicabletoim-agery[5,6].Suchasystemwouldenhancegeneralizationtonovelattacksbymodelingonlythenormalbehavior,whichinthiscontextisfrombonafidespeech.Anyspoofedutteranceswouldthenbeidentifiedasoutliersbythesystem.Recentstudies[7]suggestthatcurrentcountermeasuresys-temsdonotsufficientlymodelthebonafideclass,whereasself-supervisedlearning(SSL)front-endscanbeeffectivelyusedtodesigncountermeasures[8].Motivatedbythisclaim,weinves-tigatedusingSSLfordeepfakedetection.Inthesolutionwepropose,thisSSLdetectionapproachissupplementedbyfullysupervisedapproachesbasedonwelles-tablishedarchitecturesofthedomain.Integratingthepotentialstrengthsofthedifferentapproaches,thefinaldecisionismadebycombiningthescoresusingafusiontechnique.1.2.CombinationofsystemsAcombinationofseveraldifferentsystemsisexpectedtobemorerobusttonewattacksorconditionsthankstothecomple-mentarityofthesub-systems.Asaconsequence,weexploredthreefamiliesofmodelsforaudiodeepfakedetection.Twofamiliesofmodelsweretrainedend-to-endforbinaryclassification.ResNetmodelsarewell-knownspeakersverifi-cationarchitectures[9]andhavebeensuccessfullyappliedtotheaudiodeepfakedetectiontask[10,11].AASIST[12]isanend-to-endarchitecturewhichconstitutedoneofthebaselinesoftheASVspoof5edition.ThethirdsystemisanSSL-basedapproach.WechosetheVisionTransormerMaskedAutoEncoder(Vit-MAE)[13,14]approach,whichhasbeenshowntoworkefficientlyonsmalldatasetssuchasCIFAR10[15].AftertheSSLpretrainingphase,abinaryclassifieristrainedforaudiodeepfakedetec-tion.Thecombinationofthesesystemsisthencalibratedwithasimplelogisticregression[16],achievingaverysmallcalibra-tionerrorontheevaluationcorpusforthetargetoperatingpointoftrack1.InordertoactuallyevaluatetheeffectivenessofthissystemasaCMforSASV,wealsosubmittedittothetrack2closedcondition.WethustrainedanASVsystemabidingbytherulesofthechallenge.ThescorefusionofCMandASVwasperformedwiththerecentlyintroducednonlinearfusionmethod[17],withthescriptprovidedbytheorganizersofthechallenge.1.3.DataaugmentationsDataaugmentationsareakeycomponentofthetrainingofau-diodeepfakedetectionsystems[3].Inadditiontostandardspeechdataaugmentations,weadoptedatwo-folddataaug-mentationstrategywiththetwingoalsofincreasingrobustnesstonumericaltransmissiondegradationsandofimprovinggen-eralizationtounknownattacks.Inthecontextofnumericaltransmissions,anaudiosignal
17

Table1:Subsetsoftheasvspoof5corpus.DatasetUsage#speakers#bonafideutterances#spoofedutterances#trialsattacksasvspoof5-train-traintraining32715156130440-A01-A08asvspoof5-train-devvalidation73361332858-A01-A08asvspoof5-dev-calcalibration3921552753560138514A09-A16asvspoof5-dev-evalevaluation3931580756056143942A09-A16canbealteredinseveralways.Codecsareanessentialfunc-tioninnetworks,withtheobjectiveofadaptingthesignaltotheavailablebandwidth,whichresultsinanalterationoftheaudiosignal.Theireffectscanaccumulatedependingonthenetworkstheypassthrough.Toincreaserobustnesstonumeraltransmis-sions,weexploredasetofdataaugmentationswithdifferentcodecs[18].Basedontheperformanceontheprogressset,wepickedasetofvariouscodecswithmoderatedegradationoftheaudio.Inspiteofacompetitivepooledperformance,oursubmissionontheevaluationcorpussuffersfromasignificativedropinperformanceforseveralcodecs.Thissuggeststhatmoreaggressivecodecaugmentationscouldhaveperformedbetter,maybewiththeneedofadaptingthetrainingrecipeofthemod-els.Beyondtheirperformanceevaluatedonaspecificdataset,countermeasuresystemsarealsosensitivetotheperformanceoftheattacksystemsintendedtocircumventthem.Duringsystemdevelopment,earlyexperimentswiththeASVspoof5developmentdatasetshowedadropinperformanceduetoaconcatenation-basedattack.Fromhumanperception,thisat-tacksoundsdifferentfromtheattacksofthetrainingsetandil-lustrateshowdifficultitistogeneralizetonewattacks.Forthisclassofattacks,wedecidedtodesignaspecificdataaugmenta-tionstrategytoenhancetheglobalperformanceofourdetectionsystem.1.4.OrganizationofthepaperSection2presentsdatausageanddataaugmentationtech-niques,ourtwomaincontributionsinthispartbeingcodecaugmentationandconcatenation-basedaugmentation.Section3describesourimplementationoftheCMsystems.Section4describesourASVsystem.ExperimentalresultsarepresentedinSection5anddiscussedinSection6.2.DataInthissection,wedescribehowtheavailabledatahasbeenused.Indeed,wetookpartintheclosedconditionofthechal-lengewherethedataisrestrictedtotheASVspoof5corpus,andVoxCeleb2fortrack2.Notably,weleveragedthreekindsofdataaugmentation:standardspeechprocessingaugmentations,codecaugmentationsandaconcatenation-basedaugmentation.2.1.DatasetusageOneCMsystemwastrainedfortrack1usingonlytheASVspoof5corpus.Itwasalsousedfortrack2,incombina-tionwithanASVsystemthatwastrainedonVoxCeleb2[19].ThesplitoftheASVspoof5corpusispresentedinTable1.TheASVspoof5corpuscontainsatrainandadevsubset.Eachsetiscomposedofeightattacks.Wesplittheasvspoof5-traincorpusintotwosubsets:asvspoof5-train-devcontaining20%ofthespeakersandusedforvalidation,andasvspoof5-train-trainwiththeremainingones.TheCMsystemswerecalibratedonunknownat-tackstobemorerepresentativeofthetask.Tothisend,wesplittheasvspoof5-devcorpusintotwosub-sets:asvspoof5-dev-calusedforcalibrationandasvspoof5-dev-evalusedforevaluationonunknownat-tacks.Sincethesedatasetswerealsousedfortrack2,thesplitwasbasedontheasvspoof5-devtriallistfortrack2,withtheconstraintthatspeakersbelongingtoasametrialshouldbe-longtothesamesubet.Thereisexactlyonesplitwiththiscon-straintandthissplitisperfectlybalanced,with392and393speakerswithineachsubset.2.2.Dataaugmentations2.2.1.StandarddataaugmentationsAllCMandASVsystemsweretrainedwithasubsetofthefollowingstandardspeechdataaugmentations:•additivenoisewithartificialwhitenoiseandMU-SAN[20](noisesubsetonly),withanSNRbetween0and15dB;•reverberationwithbothartficialandrealroomimpulseresponse(RIRcorpus);•speedperturbation(×0.9or×1.1);•pitchperturbation(between−400and+400cent);•specaugment[21].2.2.2.CodecdataaugmentationsOneofthemainobjectivesoftheASVspoof5challengeistotesttherobustnessofthesystemstodifferentacousticcodecs.Accordingly,wedesignedanaugmentationstrategywhichcon-sistsofpassingasignalthroughtheencodinganddecodingpro-cessesofacodec[18].Twolistsofcodecshavebeentested:light-codec-listandfull-codec-list.TheTable2:Codecdataaugmentations.Thefirsttwocolumnsshowwhichcodecsareincludedinfull-codec-listandlight-codec-list.fulllightCodecBitraterange(kb/s)xxAAC20.0,60.0xAAC10.0xxOpus2.0xxAMRwideband14.25,32.05xAMRwideband6.60,14.25xAMRnarrowband4.75,6.70,12.20xxGSMxVOIP15.0,20.0xCODEC20.45,1.4,3.2
18

Table3:Audiodeepfakedetectionperformanceondevelopmentsets.ThesubmittedCMsystemissystem9.N°ModelDataaugmentationsdev-evalno-A12only-A12progressEEREEREERminDCFactDCFCllrEER1AASIST(baseline)15.387.8073.210.44510.47810.657317.132light-codec+B124.604.832.53----3ResNetnocodec11.781.5251.00.18180.41020.58177.374light-codec11.371.3154.80.13190.14500.27255.145full-codec12.033.9042.950.21430.21470.28388.136light-codec+B12(calonaug)0.960.861.560.07830.18370.21942.987ViT-MAEfull-codec13.525.3059.220.38890.46500.614617.448fusion6+20.890.851.180.07670.07940.11652.9696+2+70.740.641.490.07640.08480.11772.93secondisanextensionofthefirstincludingmoredegradations,particularlyintermsofacousticbandwidthreductions.CodecdetailsandrepartitioninthetwolistsaregivenTable2.2.2.3.Concatenation-basedaugmentationGuidedbythepoorperformanceofourmodelsontheA12at-tack,wedesignedanotheraugmentationfirsttotacklethiskindofattacksandtofurtherimprovethemodels.Aquickinspec-tionofthisaforementionedattacksuggestedadifferentspoofingstrategypreservinglocalspeechnaturalness.Tomimicthisattack,wedefinedaprocessformodifyinganaturalaudiosignal.Thesignalisdividedintosegmentswithrandomdurationsfollowinganormaldistributionwithmeanµandvarianceσ2.Eachsequenceisthenmodifiedbyaran-dompermutation.Finally,thetransformedsignalissimplycomposedbyconcatenatingtheelementarysignalsfromeachsegment.Thistransformation,whichwenamedB12,wasap-pliedofflineandshouldbeconsideredmoreasanattackusedfortrainingdetectionmodelsratherthanastrictaugmentationappliedonthefly.Weexcludedfromthisprocesstheaudioseg-mentswhosemeanamplitudesarebelow5e−2onanormalizedscalebetween[-1.0,1.0].TwosetsofparameterswereusedtodefinetwodifferentkindsoftransformationsclosedenoughtoA12:(µ=8e−2,σ2=2.5e−5)and(µ=0.2,σ2=2.5e−5)3.CountermeasuresystemsThreekindsofcountermeasure(CM)modelswereconsidered.First,wetrainedaResNetmodel,replicatingaspeakeridenti-ficationrecipefortheaudiodeepfakedetectiontask.WealsotrainedtheAASISTmodel[12],anend-to-endarchitectureforaudiodeepfakedetection.Finally,ourfocusshiftedtowardSelf-SupervisedLearningandaViT-MAE[13,14]waspretrainedonthetrainingdataofthechallenge.Themodelwasthenfine-tunedforbinaryclassification.Thisstrategyisafirststepto-wardsananomalydetectionsystemnotrelyingonbinaryclas-sification,whichhasbeenshowntogeneralizepoorly[2,22].3.1.ResNetThismodelisanadaptationofaVoxCelebspeakeridentificationrecipewithResNet34model[9].ResNetmodelshavebeensuc-cessfullyappliedtotheaudiodeepfakedetectiontask[10,11].Inourimplementation,theinputfeaturesarelog-melspectrogramsextractedusing40filterbanks,25mswindowand10msshiftdurations.ThemodelhasaResNet34architec-turewith2dconvolutions.Itisfollowedbyanattentivestatis-ticalpoolinglayer(meanandstandarddeviation)andaclassi-ficationhead.Ithas15.8Mparameters.Itistrainedforbinaryclassification,withthecross-entropyloss.Themodelistrainedonbalancedminibatchesofsize32withsegmentsoffixeddu-ration(3s).WeusetheAdamoptimizerwithafixedlearningrateof10−3.Themodelwithbestvalidationlossisselected.3.2.AASISTAASIST[12]isastate-of-the-artarchitectureforaudiodeep-fakedetection.Ourimplementationisverysimilartothebase-linemodelprovidedbythechallengeorganizers.Themaindif-ferenceisthatwedonotrestrictinferencetothefirstfoursec-ondsofeachutterancebutruninferenceonthetotaldurationofeachutterance.Themodeltakesrawwaveformsasinputandistrainedforbinaryclassificationtominimizethecross-entropyloss.WetrainitwiththeAdamoptimizerwithalearningrateof10−4andacosineannealingscheduler.Weusebalancedminibatchesofsize24andofsegmentsoffixedduration(3s).Themodelwithbestvalidationlossisselected.3.3.ViT-MAETheamountofdataofthechallengebeinglimited,wehadtorelyonapretrainingstrategythatcouldworkinthelow-dataregime.WechosetheViT-MAE[13,14]approach,whichhasbeenshowntoworkonsmalldatasetssuchasCIFAR10[15]Thismodeltakesasinputthelog-melspectrogramofanin-putwaveformof500msduration.Themelsareextractedusing128filterbanks,a32mswindowlengthanda8msshiftdu-ration.TheViT-MAEconsistsintrainingaViTasamaskedvariationalautoencoder.Itsinputissplitintonon-overlappingpatchesamongwhich75%arediscarded.Thetaskoftheau-toencoderistoreconstructthemissingpatchesbasedonthere-mainingones.Tocircumventthedifficultiesnaturallyarisingwhentrain-ingViTs[23,24],wemodifiedthearchitecturetouseLayer-Scale[25]anddiscardedthelearningofthenormalizationlay-ers[26].Wealsocarefullyinitializedthenetworktoensureitsoutputisstandardizedwhenitsinputis.Lastly,weusedtheConvViTapproach[24]tofurtherensurethestabilityandre-producibilityoftrainings.ThemodelpretrainedfromscratchusingSSListheConvViT-base[24].Then,athree-layerMLPwithahiddendimensionof512wastrainedontopofthefrozenencodertoclassifysegmentsof500ms.Theutterance-levelpredictionwascomputedusingtheaverageofthelogposteriorsofallnon-overlappingsegmentsof500ms.Thepretrainingwasperformedover800epochsusingthe
19

AdamWoptimizer[27]withalearningrateof8×10−4andaweightdecayof5×10−2.Weusedlinearwarmup[28]for5%ofthestepsandcosineannealingfortherestofthetraining.Themodelwaspretrainedwithaneffectiveminibatchsizeof16000segmentsof500mswithoutdataaugmentationonbothbonafideandspoofedutterances.ThetrainingoftheMLPfol-lowedthesamerecipeexceptthatthemodelwastrainedfor50epochs,thelosswasthecross-entropyanddataaugmen-tationwasused,includingthecodecaugmentationusingthefull-codec-list.3.4.FusionandcalibrationAllthethreemodels’finallayersaretrainedusingthecross-entropyloss.Weassimilatethelogitactivationsoftheoutputlayerasloglikelihoodvaluesforthehypothesesbonafideandspoofed.TheresultingLLRsarethencalibratedwithalogisticregression[16]whichistrainedontheasvspoof5-dev-caldataset.Thesamelogisticregressionmodelisusedforscore-levelsystemfusion.4.Spoofing-awareautomaticspeakerverification4.1.AutomaticSpeakerVerificationsystemAbidingbytherulesofthetrack2closedcondition,wetrainedanAutomaticSpeakerVerificationsystemontheVoxCeleb2corpus[19],withouttheMUSANspeechandmusicsubsetsfordataaugmentation.Itistrainedwithoutthecodecdataaugmen-tations.Themodelisar-vectorsystemfromtheWespeakerrecipeonVoxCeleb2[29].Theinputfeaturesarelog-melspectrogramsextractedusing80filterbanks,25mswindowand10msshiftdurations.CepstralMeanandVarianceNormalization(CMVN)isapplied.WeuseaResNet34architecture[9]withatemporalstatisticalpoolinglayer(meanandstandarddeviation).Themodelistrainedfor150epochswithanArc-marginobjective[30].Embeddingsofdimension256wereextractedfromthetrainedResNetmodelandwerecenteredwiththemeanvectorobtainedfromtheasvspoof5-train-devcorpus.Then,scoringwasperformedwithcosinesimilaritybetweentestandenrollmentembeddings.Verificationscoreswerenormal-izedwithadaptivesymmetricscorenormalization(topn=300)withacohortextractedfromVoxCeleb2[31].Finally,thespeakerverificationLLRswerecalibratedwithalogisticre-gressiontrainedontargetandnontargettrialsofthesubsetasvspoof5-dev-cal,excludingspoofedtrials.4.2.ASVandCMscorefusionNonlinearfusionoftheCMandASVscoreswasperformedwiththescorefusionscriptprovidedbythechallengeorganiz-ers[17]toproduceSpoofing-awareAutomaticSpeakerVerifi-cationscores.ThedistributionoftheCMandASVscoreswaslearnedontheasvspoof5-dev-calsubetofthedevtriallist.5.ExperimentalresultsPerformancesofthecountermeasuremodelsontheasvspoof5-dev-evalandprogressdatasetsarereportedinTable3.ForeasierreadingweonlyreportEERontheasvspoof5-dev-evalcorpusbutreportallchallengemetricsontheprogressset.TheDCFiscomputedwithanop-eratingpointgivenbythechallenge,πspf=0.05,Cmiss=1,Cfa=10,andisnormalized[1].Allsystemsarecalibratedontheasvspoof5-dev-caldataset,withtheexceptionofsystem4whichiscalibratedonanaugmentedversionofthedatasetandwhichsuffersfromahighcalibrationerrorontheprogressset.System2hasnotbeenevaluatedontheprogresssetduringtheprogressphaseofthechallenge.Themodelshavealsobeenevaluatedontheasvspoof5-train-devcorpus.AllmodelsexhibitanEERbelow1%onthiscorpus,confirmingthatdetectionofknownattacksisaneasytask.5.1.Effectofdataaugmentationoncountermeasuresys-temsDataaugmentationtechniqueshavebeenselectedbasedonexperimentswiththeResNetarchitecture.Weobservethatthedifferentversionsofcodecaugmentation(nocodec,light-codec-listandfull-codec-list)donothaveasignificantimpactonperformanceontheasvspoof5-dev-evalcorpus.Theimpactisdifferentontheprogresssetwherethelight-codec-listaugmen-tationachievesasignificantimprovementovernocodec.Weassumethatthelowperformanceofthefull-codec-listaugmentationontheprogresssetmaybeexplainedbythebadconvergenceofthemodel.Bettergeneralizationofamodelwithfull-codec-listaugmentationmaybeachievedwithacarefultuningoftheoptimizationhyperparameters.Thecodecaugmentationsduringthemodeltrainingphase,nonetheless,improvescalibrationofthemodel.ThedifferencebetweenactDCFandminDCFforthenocodecmodel(0.4102vs0.1818)isreducedforthelight-codec-list(0.1450vs0.1319)andfull-codec-list(0.2147vs0.2143).Itisim-portanttonotethatdataaugmentationwasappliedexclusivelytothetrainingsetofthemodelandnottothecalibrationdataset.Duringthesystemdevelopmentphase,weperformedper-attackevaluationofthesystems.Wenoticedthatthehigher-rorratesontheasvspoof5-dev-evalcorpuswasmainlyduetotheA12attackwherethesystems1,3,4and7achieveworstthanrandomperformance.Toillustratethiseffect,weprovideperformancemetricsseparatelyfortheA12attackandforthesetofallotherattacksexcludingA12.WeobservethattheintroductionoftheB12augmentation(system6)drasticallyimprovesperformanceontheA12attack.Thebestcombinationofaugmentations,light-codec-listaugmentationandB12augmen-tation,hasbeenselectedtotraintheResNetmodel.AppliedtotheAASISTarchitecture,itachievesasignificantimprovement(comparisonofsystems1and2).BecauseoftimeconstraintsTable4:AutomaticSpeakerVerificationEqualErrorRate(%)onVoxCeleb1andASVspoof5developmentsetswithandwith-outspeechusedindataaugmentation.OnlytheASVsystemtrainedwithoutMUSANspeechandmusicisusedforscoring.vox1-Ocleanvox1-Ecleanvox1-Hcleanasvspoof5-dev(nospoof)w/MUSANspeech&music0.7870.9641.726-w/oMUSANspeech&music0.8510.9901.7871.285
20

Table5:Performanceonprogressandondevtrack2.Thesubmittedsystemcorrespondstothelastrow.CMmodelASVmodelasvspoof5-dev-evalprogressmina-DCFmint-DCFt-EERmina-DCFmint-DCFt-EER6ResNet0.02210.10700.900.09860.18264.1190.02100.10050.850.10060.18594.17duringthechallenge,onlythefull-codec-listaugmen-tationhasbeenappliedtotheViT-MAEmodel(system7)forthebinaryclassificationphase(notpretraining).Thesubmittedcountermeasuresystemforbothtracksisthesystem9,fusionofsystems6(resnetwithlight-codec-listandB12aug-mentations),2(AASISTwithlight-codec-listandB12augmentations)and7(VITMAEwithfull-codec-listaugmentation).5.2.Spoofing-awareautomaticspeakerverificationTable4reportsindicativeperformanceoftheASVsystemonVoxCeleb1whenthemodelistrainedwithandwithoutMU-SANspeechandmusicsplitsfordataaugmentation.Asex-pected,whenMUSANspeechandmusicsplitsareused,themodelperformsbetterthanwhentheyarenotused(0.787vs0.851onvox1-O-clean).However,theincreaseinperfor-manceismodest,suggestingthattheResNet34doesnotheavilydependonMUSANspeechandmusicsplitstoachieveproperperformance.Ontheasvspoof5-devset,withspoofedtri-alsremovedfromscoring(classicEERwithtargetandnon-targetpairs),theASVmodelperformswellwithanEERof1.285%,indicatingthatthespeakerverificationtaskisrela-tivelyeasyonthedevset.InTable5,weevaluatetheSASVsystemsconstitutedofthecombinationoftheASVsystemwithtwoCMsystems:thebestsinglesystem(system6)andthefusionofResNet,AASISTandViT-MAE(system9).Forconsistencybetweentracks1and2,wesubmittedthecombinationwiththefusionsystem,eventhoughitsperformanceisslightlyworseontheprogressdataset.5.3.PerformanceontheevaluationcorpusInTables6and7,wereporttheperformanceofthesubmittedsystemsontheevaluationcorpusfortracks1and2closedcon-dition.Thislevelofperformancelooksreasonablebutshowsadropincomparisonwiththedevandprogresscorpora.Wenoticethatthesystemisremarkablywellcalibratedforthetar-getoperatingpointoftrack1,withaverysmallgapbetweenactDCFandminDCF.Theevaluationdatasetisdescribedin[4]whereoursubmis-sionisreferredasT24.InFigures1and2,weplottheactDCFofthesubmittedsystemfortrack1foreachattackandcondi-tion,andthemina-DCFfortrack2.First,weobservethatthesystemperformswellintheabsenceofcodec.Thepooledact-DCFresultwithnocodec(0.186)isonlytwicethevalueontheprogressset(0.085)despitethepresenceofunknownadversar-ialattacks.ThereisnocatastrophicbehaviorcomparabletotheA12attackobservedinthedevcorpus.Additionally,thenormal-izedactDCFremainsbelow1.0acrossallattacksandcondi-tions(notworstthanadefaultsystem).Forthenocodeccon-dition,thesystemachievesanactDCFbelow0.05foreightofthesixteenevaluationattacks.TheadversarialattackssuchasMalafide[32](A18andA20)andMalacopula[33](A27,A30,A31,A32)areveryeffectiveonthesubmittedsystemandareresponsibleofthemajorityoferrorsonthenocodecconditionOnthecontrary,thesystemsuffersfromasignificativedropinperformanceformostcodecs,untilathree-foldincreaseoftheactDCFforcodec-7comparedtothenocodeccondi-tion.8kHzbandwidthconditions(codec-8,codec-9,codec-10,codec-11)arechallengingbuttheworstactDCFvaluesareob-tainedwhentheEncodec[34]neuralaudiocompressionisap-plied(codec-4andcodec-7).6.Discussion6.1.GeneralizationtounknownattacksThegeneralizationtoaprioriunknownattacksisthemainchallengeofdeepfakedetection.ThedifficultytodetecttheA12attackofthedevelopmentcorpusisaperfectillustra-tionofthisproblem.Oursolutionwastointroduceaspecificconcatenation-baseddataaugmentation,whichbasicallysolvesthisproblemonthedevelopmentcorpusandseemsusefulontheprogressdataset.Fortunately,theproposedcountermeasuresystemsgeneralizequitewelltotheattacksoftheevaluationcorpus,withnocatastrophicbehaviorcomparablewithattackA12.Butwehadnoguaranteethatthisapproachwouldgener-alize.Theproposedsolutionwastoaddaugmentedspoofedutterancesmorerepresentativeofaclassofnewtargetattackstothetrainingset.Thisapproachexposesthepractitionertoapotentialcatastrophicbehaviorwhenexposedtonewattacksbeingverydifferentfromtheattacksofthetrainingset.Webe-lievethatasimplebinaryclassificationapproachisinsufficienttoestablishtheleveloftrustrequiredforeffectivelyhandlingnewattacksinpracticalapplications.Weplantoexploreaddi-tionalanomalydetectionmethodsthatfocusonamoredetailedmodelingofbonafidespeech.ThiswasthemainmotivationofourworkontheViT-MAEsystempresentedinsubsection3.3,eventhoughwewereunabletoimplementanefficientanomalydetectionCMwithinthechallengetimeline.6.2.RobustnesstocodecdegradationRobustnesstocodecdegradationcanbepartiallyachievedwithcodecdataaugmentationofthetrainingset.Thisapproachachievedsignificantgainsonthedevelopmentandprogresssets,andmayberesponsibleofthecompetitiveperformanceofthesubmittedsystemontheevaluationcorpus.Weselectedasetofcodecaugmentationswithmoderatedegradations,mostofthemdonotoperateafrequencybandreduction,whichhavebeensuccessfullyappliedtotheCMsystemswithouttheneedtomodifytheoptimizationhyper-parameters.Theobservedperformancedropontheevaluationsetforvariouscodecssuggeststhatmoreaggressivecodecdataaugmentationmethodscouldhavebeennecessary.Eventhoughthesekindofaugmentationswereexploredduringthedevelop-mentphaseofoursolution,wedidnotselectthemduetotheirlowerperformanceonnocodecconditions.Theireffectiveap-
21

Figure1:actDCFofthesubmittedsystemontrack1evaluationcorpus.Attacksandcodecsaredescribedin[4].plicationtotheCMsystemsseemsreachablebutwillprobablyneedanadaptationoftheoptimizationhyperparameters.More-overanincreasedperformanceforspoofing-awarespeakerver-ificationcanbeexpectedfromtheapplicationofcodecspecificdataaugmentationsonthespeakerverificationsystem.6.3.CalibrationPracticaluseofacountermeasuresystemrequiresscorestobecalibrated.ForthefirsttimetheASVspoof5challengeencour-agedparticipantstosubmitcalibratedLLRs[4].Wecalibratedthesystemwithasimplelogisticregressionandobtainedaverylowcalibrationerrorontheevaluationcorpus.However,thereisaninherentdifficultyincalibratingacountermeasuresystem,duefirstlytounknownattacks,butalsotoensemble-basedar-chitectures,wheredifferentsubsystemsmaybetrainedondif-ferentsubsetsofattacksandreactdifferentlydependingontheattack.Wehopethattherewillbemoreinterestinthecalibra-tionofcountermeasuresystems,andweplantostudythisissueingreaterdepthoverthecomingmonths.Table6:Performanceontheevaluationdatasetofthesubmit-tedsystemfortrack1minDCFactDCFCllrEER0.2970.2980.41810.43Table7:Performanceontheevaluationdatasetofthesubmit-tedsystemfortrack2mina-DCFmint-DCFt-EER0.2950.6189.58Figure2:mina-DCFofthesubmittedsystemontrack2evalua-tioncorpus.7.ConclusionThispaperdescribesthejointsubmissionofInriaD´efenseetS´ecurit´eandStoryzyfortheASVspoof5challengeclosedcon-dition.Thesubmittedcountermeasuresystemisthecombina-tionofthreemodelstrainedforbinaryclassification:ResNet,AASISTandViT-MAE.TheViT-MAEmodelispretrainedwithamaskedautoencoderobjective.Dataaugmentationsareappliedtoenforcerobustnesstodatatransmissionandtoim-proveperformanceonconcatenationattacks.Fortrack2,thesystemiscombinedwithacustomautomaticspeakerverifica-tionsystem,trainedonVoxCeleb2withoutMUSANspeechandmusicsubsetstoabidebytherulesofthechallenge.Thesub-mittedsystemachievesacompetitiveperformanceontheevalu-ationcorpusofbothtracks,whichisconstitutedofchallengingadversarialattacksandcodecconditions.Itisparticularlywellcalibratedforthetargetoperatingpointoftrack1.8.AcknowledgementsThisworkwasperformedusingHPCresourcesfromGENCI-IDRIS(GrantAD011014982).9.References[1]HectorDelgado,NicholasEvans,JeeweonJung,TomiKinnunen,IvanKukanov,KongAikLee,XuechenLiu,Hye-jinShim,HemlataTak,MassimilianoTodisco,XinWang,andJunichiYamagishi,“ASVspoof5evaluationplan(phase2),”online,accessed31-July-2024.[2]NicolasM.M¨uller,PavelCzempin,FranziskaDieck-mann,AdamFroghyar,andKonstantinB¨ottinger,“Doesaudiodeepfakedetectiongeneralize?,”inProc.Inter-speech,2022,pp.2783–2787.[3]XuechenLiu,XinWang,MdSahidullah,JosePatino,H´ectorDelgado,TomiKinnunen,MassimilianoTodisco,JunichiYamagishi,NicholasEvans,AndreasNautsch,
22

andKongAikLee,“ASVspoof2021:Towardsspoofedanddeepfakespeechdetectioninthewild,”inIEEE/ACMTransactionsonAudio,Speech,andLanguageProcess-ing,2023,vol.31,pp.2507–2522.[4]XinWang,H´ectorDelgado,HemlataTak,Jee-weonJung,Hye-jinShim,MassimilianoTodisco,IvanKukanov,XuechenLiu,MdSahidullah,TomiKinnunen,NicholasEvans,KongAikLee,andJunichiYamagishi,“ASVspoof5:Crowdsourcedspeechdata,deepfakes,andadversarialattacksatscale,”inASVspoofWorkshop2024(accepted),2024.[5]JianweiFei,YunshuDai,PeipengYu,TianrunShen,Zhi-huaXia,andJianWeng,“Learningsecondorderlocalanomalyforgeneralfaceforgerydetection,”inProc.IEEE/CVFCVPR,2022,pp.20238–20248.[6]ChaoFeng,ZiyangChen,andAndrewOwens,“Self-supervisedvideoforensicsbyaudio-visualanomalyde-tection,”inProc.IEEE/CVFCVPR,2023,pp.10491–10503.[7]Hye-jinShim,MdSahidullah,Jee-weonJung,ShinjiWatanabe,andTomiKinnunen,“Beyondsilence:Biasanalysisthroughlossandasymmetricapproachinaudioanti-spoofing,”arXivpreprintarXiv:2406.17246,2024.[8]XinWangandJunichiYamagishi,“Investigatingself-supervisedfrontendsforspeechspoofingcountermea-sures,”inProc.Odyssey:TheSpeakerandLanguageRecognitionWorkshop,2022,pp.100–106.[9]Pierre-MichelBousquet,MickaelRouvier,andJean-FrancoisBonastre,“Reliabilitycriterionbasedonlearning-phaseentropyforspeakerrecognitionwithneu-ralnetwork,”inProc.Interspeech,2022,pp.281–285.[10]WeichengCai,HaiweiWu,DanweiCai,andMingLi,“TheDKUreplaydetectionsystemfortheASVspoof2019challenge:Ondataaugmentation,featurerepresen-tation,classification,andfusion,”inProc.Interspeech,2019,pp.1023–1027.[11]TianxiangChen,ElieKhoury,KedarPhatak,andGaneshSivaraman,“PindropLabs’submissiontotheASVspoof2021challenge,”inProc.2021EditionoftheAutomaticSpeakerVerificationandSpoofingCountermeasuresChal-lenge,pp.89–93.[12]Jee-weonJung,Hee-SooHeo,HemlataTak,Hye-jinShim,JoonSonChung,Bong-JinLee,Ha-JinYu,andNicholasEvans,“AASIST:Audioanti-spoofingusingin-tegratedspectro-temporalgraphattentionnetworks,”inProc.IEEEICASSP,2022,pp.6367–6371.[13]KaimingHe,XinleiChen,SainingXie,YanghaoLi,Pi-otrDollar,andRossGirshick,“Maskedautoencodersarescalablevisionlearners,”inProc.IEEE/CVFCVPR,2022,pp.15979–15988.[14]DaisukeNiizumi,DaikiTakeuchi,YasunoriOhishi,NoboruHarada,andKunioKashino,“Maskedspec-trogrammodelingusingmaskedautoencodersforlearn-inggeneral-purposeaudiorepresentation,”inVolume166:HolisticEvaluationofAudioRepresentations.2022,PMLR.[15]KentaroYoshioka,“https://github.com/kentaroy47/vision-transformers-cifar10,”online,accessed31-July-2024.[16]LucianaFerrer,“https://github.com/luferrer/calibrationtutorial,”online,accessed31-July-2024.[17]XinWang,TomiKinnunen,LeeKongAik,Paul-GauthierNoe,andJunichiYamagishi,“RevisitingandImprovingScoringFusionforSpoofing-awareSpeakerVerificationUsingCompositionalDataAnalysis,”inProc.Interspeech(accepted),2024.[18]RohanKumarDas,“Known-unknowndataaugmentationstrategiesfordetectionoflogicalaccess,physicalaccessandspeechdeepfakeattacks:ASVspoof2021,”in2021EditionoftheAutomaticSpeakerVerificationandSpoof-ingCountermeasuresChallenge,2021,pp.29–36.[19]JoonSonChung,ArshaNagrani,andAndrewZisserman,“VoxCeleb2:Deepspeakerrecognition,”inProc.Inter-speech,2018,pp.1086–1090.[20]DavidSnyder,GuoguoChen,andDanielPovey,“MU-SAN:Amusic,speech,andnoisecorpus,”2015,arXiv,arXiv:1510.08484.[21]DanielS.Park,WilliamChan,YuZhang,Chung-ChengChiu,BarretZoph,EkinD.Cubuk,andQuocV.Le,“SpecAugment:Asimpledataaugmentationmethodforautomaticspeechrecognition,”inProc.Interspeech,2019,pp.2613–2617.[22]DavideAlessandroCoccomini,RobertoCaldelli,FabrizioFalchi,andClaudioGennaro,“Onthegeneralizationofdeeplearningmodelsinvideodeepfakedetection,”inJournalofImaging.2023,vol.9,p.89,MultidisciplinaryDigitalPublishingInstitute.[23]HugoTouvron,MatthieuCord,MatthijsDouze,Fran-ciscoMassa,AlexandreSablayrolles,andHerv´eJ´egou,“Trainingdata-efficientimagetransformers&distillationthroughattention,”inProc.ICML.2021,pp.10347–10357,PMLR.[24]TeteXiao,MannatSingh,EricMintun,TrevorDarrell,Pi-otrDoll´ar,andRossGirshick,“Earlyconvolutionshelptransformersseebetter,”inAdvancesinneuralinforma-tionprocessingsystems,2021,pp.30392–30400.[25]HugoTouvron,MatthieuCord,AlexandreSablayrolles,GabrielSynnaeve,andHerveJegou,“Goingdeeperwithimagetransformers,”inIEEE/CVFICCV,2021,pp.32–42.[26]JingjingXu,XuSun,ZhiyuanZhang,GuangxiangZhao,andJunyangLin,“Understandingandimprovinglayernormalization,”inAdvancesinneuralinformationpro-cessingsystems,2019,pp.4381–4391.[27]IlyaLoshchilovandFrankHutter,“Decoupledweightde-cayregularization,”inProc.ICLR,2019.[28]JerryMaandDenisYarats,“Ontheadequacyofuntunedwarmupforadaptiveoptimization,”inProc.AAAICon-ferenceonArtificialIntelligence,vol.35,pp.8828–8836.[29]ShuaiWang,ChengdongLiang,XuXiang,BingHan,ZhengyangChen,HongjiWang,andWenDing,“WespeakerbaselinesforVoxSRC2023,”2023,arXiv:2306.15161.[30]JiankangDeng,JiaGuo,NiannanXue,andStefanosZafeiriou,“Arcface:Additiveangularmarginlossfordeepfacerecognition,”inProc.IEEE/CVFCVPR,2019,pp.4690–4699.[31]PavelMatˇejka,OndˇrejNovotn´y,OldˇrichPlchot,Luk´aˇsBurget,MireiaDiezS´anchez,andJanˇCernock´y,“Anal-ysisofscorenormalizationinmultilingualspeakerrecog-nition,”inProc.Interspeech,2017,pp.1567–1571.
23

[32]MichelePanariello,WanyingGe,HemlataTak,Massim-ilianoTodisco,andNicholasEvans,“Malafide:anoveladversarialconvolutivenoiseattackagainstdeepfakeandspoofingdetectionsystems,”inProc.Interspeech,2023,numberarXiv:2306.07655,pp.2868–2872.[33]MassimilianoTodisco,MichelePanariello,XinWang,HectorDelgado,Kong-AikLee,andNicholasEvans,“Malacopula:Adversarialautomaticspeakerverificationattacksusinganeural-basedgeneralisedhammersteinmodel,”inProc.ASVspoof5workshop(submitted),2024.[34]AlexandreD´efossez,JadeCopet,GabrielSynnaeve,andYossiAdi,“Highfidelityneuralaudiocompression,”inTransactionsonMachineLearningResearch,2023.