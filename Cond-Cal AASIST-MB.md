太好了—下面给你一份**从零到定版**的、一步一步的**完整执行方案**。按顺序做就行；每一步都写清楚：要做什么、为什么、怎么做、成功判据（打勾标准）、风险与回滚。你**不需要写一行代码**也能把活安排下去；工程同学按这个清单实施即可。

---

# 目标与约束（放在最前面统一共识）

* **任务**：ASVspoof 5，**Track 1（Closed）**，在**单模型、低复杂度**前提下逼近/超越头部成绩；**actDCF≈minDCF**（便于部署）。
* **创新点**（论文可写）：1) **CodecMix++（短链+课程采样）**，2) **BAS（隐性边界对抗拼接）**，3) **Cond-Cal（条件化线性校准）**，4) **AASIST-MB（共享式多带）**，5)（可选）**PhaseResidual（相位残差支路）**。
* **复杂度红线**：参数与 FLOPs 总增幅 **≤ +10%**（不含可选 TTA）。训练时长相对基线 **+15%\~25%**；推理时延 **+8%\~10%**。

---

# 阶段 0｜准备与基线冻结（半天）

## 步骤 0.1｜锁定基线

* **做什么**：把你们当前 AASIST 的训练/推理配置**冻结**（版本化保存配置文件、随机种、依赖版本）。
* **为什么**：后续所有提升都要与**同一基线**对比，避免“配置变了”导致的误判。
* **成功判据**：用相同配置重复训练 **2 次**，Dev 上 pooled **minDCF 波动 <3%（相对）**；保存模型与日志。

## 步骤 0.2｜统一评测输出

* **做什么**：固化一个“**一键评测脚本**”：

  * 同时输出：**minDCF、actDCF、EER、(actDCF−minDCF) gap**；
  * 输出**按攻击 × 编解码**细分表（热力图或表格都可）；
  * 记录**吞吐/显存**与**单条推理时延**。
* **为什么**：之后每一步的成败都靠它来“说话”。

---

# 阶段 1｜数据通路与在线增强（高优先级，先做）

> 目标：**不重算全库 .npy**，把强增强“搬到在线”，省时省盘；必要时用**小缓存池**兜底。

## 步骤 1.1｜双路径 DataLoader（wav 主、npy 辅）

* **做什么**：训练时 **70–80%** 样本走 **WAV→在线增强→特征**，**20–30%** 样本走\*\*已有 NPY（干净特征）\*\*直通。
* **工程要点**：

  * DataLoader 支持**两条分支**和**可配概率**；
  * 开 `num_workers=8–16`，`prefetch_factor≥2`，`pin_memory=True`；
  * 随机数由 `(sample_id, epoch)` 派生，确保**可复现**。
* **成功判据**：GPU 利用率 ≥ **95%**；I/O 不拉胯。

## 步骤 1.2｜CodecMix++（短链 + 课程采样）

* **做什么**：对进入 WAV 分支的样本，**30–40% 概率**施加**1–2 个效果**组成的“短链”：

  * **带宽/重采样类**：低通（8/12 kHz 截止）、微重采样抖动；
  * **编解码近似**：低码率 **MP3 (32–96 kbps)**、**Opus (8–24 kbps)**、**Speex 8k/16k**、以及**Encodec-like 近似**（用带宽+量化噪声/EQ 模拟，不引重依赖）；
  * **动态范围/响度**：轻 DRC、微量增益漂移；
  * **传输环境**：短混响（小 T60）、-20\~0 dB SNR 的噪声/音乐**微混合**（以编解码效应为主，噪声为辅）。
* **课程采样**：

  * 训练前 **30%** 步数，提高“难 codec”（Speex/超低码率 MP3/Encodec-like）的采样概率；
  * 之后恢复均衡抽样。
* **小缓存池（强烈建议）**：

  * 对**最难的 2–3 类**（如 Speex、32 kbps MP3、Encodec-like）在**一个固定子集**上**离线转码**成小分片（tar/LMDB），在多个 epoch 复用；
  * 其余效果**在线**即可。
* **成功判据**：

  * Dev 上 pooled **minDCF 相对下降 ≥ 10–15%**；
  * 难 codec 子集（Speex/低码率 MP3/Encodec-like）明显改善；
  * 训练速度开销控制在 **+5%\~12%** 范围。
* **回滚规则**：若早期不收敛 → 降低噪声/混响强度，先以**带宽+低码率 MP3**为主；课程曲线更平缓。

## 步骤 1.3｜BAS（Boundary Adversarial Splicing，隐性边界拼接）

* **做什么**：对**10–15%** 的训练样本做“隐性拼接”（专打 A12 类）：

  * 选**同说话人**的两段短片（或同一段不同切片）；
  * 边界处随机使用：**1–5 ms 超短 cross-fade**、**±1–2 dB 幅度错配**、**轻微 DC 偏置差**三者之一；
  * 标签保持不变（不引混标）。
* **成功判据**：A12/拼接相关子集 **minDCF 相对下降 ≥ 15%**，整体不退化。
* **回滚规则**：若总体退化 → 将触发率降到 **5–8%**，或仅在 **spoof 类**样本上应用。

---

# 阶段 2｜训练目标与校准（打通 minDCF→actDCF 的最后一公里）

> 目标：**风险感知训练** + **条件化线性校准**，让 **actDCF≈minDCF**。

## 步骤 2.1｜Risk-Weighted BCE + 温度头

* **做什么**：

  * **风险加权 BCE**：按评测代价设定类别权重（起步 **FA\:Miss = 1:10**），并对“**靠近决策阈值**”的样本乘以一个**邻域增益**（靠近越多权重越大）；
  * **温度头**：在分类 logit 上乘一个**可学习温度 T（标量）**，与模型同训。
* **为什么**：把学习重心放到 **minDCF 敏感区域**，同时让输出更接近“**似然比形态**”，为校准打基础。
* **成功判据**：Dev 上 **(actDCF − minDCF) 的 gap** 相比前一步**缩小 ≥ 0.02**；pooled minDCF 至少不退。

## 步骤 2.2｜Cond-Cal（条件化逻辑回归校准）

* **做什么**：在 Dev 上，用“**模型分数 + 4 个自统计特征**”训练**逻辑回归**做线性校准（输出 LLR）；

  * 4 个自统计特征：①**高频能量占比（带宽 proxy）**，②**SNR 粗估**，③**谱平坦度均值**，④**有效语音占比/时长**；
  * 推理时：对每条音频先算这 4 个统计，再把\*\*\[分数, 4 特征]**喂给线性层→得到**校准后分数\*\*。
* **为什么**：不同 codec/带宽对分数分布的**整体平移**是 actDCF 变差主因；**条件化线性校准**以**接近 0 成本**消除偏移。
* **成功判据**：Dev 上 **actDCF≈minDCF（gap ≤ 0.01–0.02）**；Progress 集上**不崩**。
* **回滚规则**：若过拟合 → 只保留 **带宽占比 + 谱平坦度** 两项；或改为**分段线性**但仍然 O(1) 成本。

---

# 阶段 3｜结构小改（在预算内换“硬分”）

> 目标：在\*\*≤+10%\*\* 成本内，进一步提升对编解码/带宽移位和相位伪影的鲁棒性。

## 步骤 3.1｜AASIST-MB（共享式多带）

* **做什么**：

  * 将输入按**固定三带**切片（例如低/中/高；分界可设约 1.5 kHz / 3.5 kHz 或等 mel 段）；
  * 送入**共享权重**的 group-conv 前端（多带但**不复制参数**），再用**轻量 SE 门控**做带间融合，回到原 AASIST 干路；
  * 控制增量：参数 **< +5%**，FLOPs **< +7%**。
* **为什么**：编解码伪影在**不同子带分布差异**显著；共享式多带能增强分辨率而**不爆参数**。
* **成功判据**：在阶段 2 的基础上，pooled **minDCF 额外相对下降 ≥ 5–8%**；难 codec 子集继续下降；推理时延增幅符合预算。
* **回滚规则**：若参数溢出 → 降低门控维度；如仍不稳 → 改为**二带**（低/高）。

## 步骤 3.2（可选）｜PhaseResidual（相位残差支路）

* **做什么**：从 STFT 派生 2–3 个**相位/群时延**相关通道（逐帧标量），过**极薄 depthwise-conv + 1×1 投影（8–16 维）**，以**残差**方式注入主干早中层。
* **为什么**：合成/编解码常有**相位异常**；极简支路就能吃到红利。
* **成功判据**：额外**相对下降 ≥ 3–5%**（pooled minDCF）；对 Encodec-like/低码率 MP3 子集收益更明显；增量成本 **≤ +4% 参数、+3% FLOPs**。
* **回滚规则**：若收益不稳定 → 暂不启用，保持 3.1 定版。

---

# 阶段 4｜定版与（可选）微调

## 步骤 4.1｜定版模型（不使用多模型与重 TTA）

* **做什么**：以**单模型**为最终系统；默认**不启用 TTA**。若线上预算允许、分数还差一点，可做**一次**极轻 TTA（不同起点裁剪或 ±1% 速率微扰，**×1 前向**）。
* **成功判据**：TTA 带来 **2–5% 相对**收益且不破坏延时约束；否则关闭 TTA。

## 步骤 4.2｜完整评测与产物

* **做什么**：在 Dev/Progress 输出：

  * **pooled** 的 minDCF/actDCF/EER；
  * **按攻击 × 编解码**细分表；
  * **训练/推理资源**（吞吐、显存、时延）；
  * 保存：模型权重、配置、校准参数、评测报告（PDF/表格）。
* **成功判据**（对比阶段 0 基线）：

  * **pooled minDCF 累计相对下降 ≥ 20–30%**；
  * **actDCF − minDCF ≤ 0.02**；
  * 难子集（Speex/低码率 MP3/A12/Encodec-like）**持续下降**；
  * 单模推理参数/FLOPs **≤ +10%**；（若启用 TTA，说明单次成本不变）

---

# 阶段 5｜消融、风险与论文材料（为投稿/汇报准备）

## 步骤 5.1｜消融顺序（每次只改一件事）

1. **仅 CodecMix++**（vs. 基线）
2. **+ BAS**
3. **+ 风险加权 BCE + 温度头**
4. **+ Cond-Cal（校准）**
5. **+ AASIST-MB**
6. **(+ PhaseResidual，可选)**
7. **(+ TTA 或 Snapshot→Single 蒸馏，二选一，作为附录）**

* **输出**：每一步的 pooled 与细分表（同一版式），画出**累计提升曲线**。

## 步骤 5.2｜常见失败与快速回滚

* **训练不收敛**：先关掉 BAS，把 CodecMix++ 的噪声/混响强度降一半，仅保留**带宽+低码率 MP3** 1 个效果；
* **actDCF 居高不下**：确认温度头在训、Cond-Cal 的 4 特征是否计算正确；如仍不稳，先退到**两特征（带宽+平坦度）**；
* **延时超标**：PhaseResidual 先关；多带门控降维；TTA 必关。

## 步骤 5.3｜论文/答辩材料清单

* **方法图**：四个创新点的小图（CodecMix++ 课程曲线、BAS 边界示意、Cond-Cal 框图、AASIST-MB 结构草图）；
* **主表**：与基线对比的 pooled 指标 + 资源占用；
* **细分图**：按**攻击 × 编解码**的热力图（标出难点的改善）；
* **校准图**：actDCF 与 minDCF 的对比柱状或折线；
* **消融表**：按 5.1 的顺序累加展示；
* **复杂度表**：参数、FLOPs、推理时延的增量统计。

---

## 资源与排期（供项目经理排工）

* **训练时间**：相对当前基线 **+15%\~25%**（主要来自在线增强与小幅结构改）；
* **推理时延**：**+8%\~10%**（来自 AASIST-MB/PhaseResidual；不启用 TTA 时）；
* **人力投入**：

  * 阶段 1（数据与增强）：**1 人·周**（含小缓存池）；
  * 阶段 2（损失与校准）：**0.5 人·周**；
  * 阶段 3（结构小改）：**1 人·周**；
  * 阶段 4–5（评测与材料）：**0.5 人·周**。

> 以上是**保守估计**，以你们已有基础为前提；不包含大规模分布式/多卡调优。

---

# 一页式清单（抄走就能干）

1. **冻基线**（配置/脚本/指标一致）✅
2. **双路径 DataLoader**（WAV 主、NPY 辅；高并发、复现性）✅
3. **CodecMix++ 上线**（短链增强 + 课程采样 + 难 codec 小缓存池）✅
4. **BAS 上线**（10–15% 触发；隐性边界三选一）✅
5. **风险加权 BCE + 温度头**（把学习重心放在代价敏感区）✅
6. **Cond-Cal 校准**（分数 + 4 自统计 → 线性校准；act≈min）✅
7. **AASIST-MB**（共享式多带，<+5% 参、<+7% FLOPs）✅
8. **（可选）PhaseResidual**（相位残差，<+4% 参、<+3% FLOPs）⬜
9. **（可选）TTA ×1 或 Snapshot→Single 蒸馏**（二选一，预算允许）⬜
10. **定版与消融**（主表、细分表、校准图、复杂度表全部齐活）✅

---

**一句话收尾**：先把**在线增强（CodecMix++）**和**BAS**做起来，再用**风险加权 + Cond-Cal**把 **actDCF 拉齐**；最后在预算内加上**AASIST-MB**（必要时加 PhaseResidual）。按这条路走，你能在**不重算全库、不上多模型**的前提下，拿到**大幅 minDCF 改善**和**可部署的校准**，而且每一步都有清晰“打勾标准”和快速回滚策略。
