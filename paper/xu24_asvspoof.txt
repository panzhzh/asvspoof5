The Automatic Speaker Verification Spoofing Countermeasures Workshop (ASVspoof 2024)
31 August 2024, Kos, Greece

64

10.21437/ASVspoof.2024-10

SZU-AFSAntispoofingSystemfortheASVspoof5ChallengeYuxiongXu1,JiafengZhong1,SenguiZheng2,ZefengLiu1,BinLi1∗1GuangdongProvincialKeyLaboratoryofIntelligentInformationProcessing,ShenzhenKeyLaboratoryofMediaSecurity,andSZU-AFSJointInnovationCenterforAITechnology,ShenzhenUniversity,Shenzhen,China2AfirstsoftTechnologyGroupco.,Ltd.,Shenzhen,China{xuyuxiong2022,jiafengzhong2022}@email.szu.edu.cn,1225620446@qq.comliuzefeng2021@email.szu.edu.cn,libin@szu.edu.cnAbstractThispaperpresentstheSZU-AFSanti-spoofingsystem,de-signedforTrack1oftheASVspoof5Challengeunderopenconditions.Thesystemisbuiltwithfourstages:select-ingabaselinemodel,exploringeffectivedataaugmentation(DA)methodsforfine-tuning,applyingaco-enhancementstrat-egybasedongradientnormawareminimization(GAM)forsecondaryfine-tuning,andfusinglogitsscoresfromthetwobest-performingfine-tunedmodels.ThesystemutilizestheWav2Vec2front-endfeatureextractorandtheAASISTback-endclassifierasthebaselinemodel.Duringmodelfine-tuning,threedistinctDApolicieshavebeeninvestigated:single-DA,random-DA,andcascade-DA.Moreover,theemployedGAM-basedco-enhancementstrategy,designedtofine-tunetheaug-mentedmodelatbothdataandoptimizerlevels,helpstheAdamoptimizerfindflatterminima,therebyboostingmodelgeneral-ization.Overall,thefinalfusionsystemachievesaminDCFof0.115andanEERof4.04%ontheevaluationset.1.IntroductionRecentadvancementsinArtificialIntelligenceGeneratedCon-tent(AIGC)havesignificantlyenhancedthenaturalness,fi-delity,andvarietyofspeech.Unfortunately,thisprogresshasresultedinaproliferationofforgeriesthatcanbealmostin-distinguishablefromauthenticspeechtothehumanauditorysystem.Concurrently,automaticspeakerverification(ASV)systemshavebecomeincreasinglysusceptibletospoofinganddeepfakeattacks,inwhichattackersproduceconvincinglyre-alisticsimulationsofthetargetspeaker’svoice[1].Thepoten-tialmisuseofspoofedspeechpresentssignificantsocietalrisks.Therefore,developingarobustandgeneralizableanti-spoofingsystemtocounterthesethreatshasemergedasacriticalre-searchimperative.TheASVspoofchallenges[2,3,4,5,6]havesignificantlyboostedinterestindevelopingrobustdetectionsolutionsforspoofinganddeepfakeattacks,therebyenhancingthesecu-rityandreliabilityofASVsystems.Thesechallengesprovidestandardizedbenchmarkprotocolsandcomprehensiveevalua-tiondatasets.What’smore,thelastfourASVspoofchallenges[2,3,4,5]havepromptedtheproposalofnumerousinnovativespoofingdetectionmethods[7,8,9,10].Heldin2024,theASVspoof5Challenge[6]presentstwodistinctconditions,openandclosed,forbothTrack1whichfocusesonstandalonespeechdeepfakedetection,andTrack2*CorrespondingauthorFigure1:IllustrationoftheSZU-AFSanti-spoofingsystem.Thecoloredboxesrepresentfourstagesofthesystem,witheachstagelabeledbymodelIDsfromAtoD.Thebest-performingmodelineachstageanditsIDnumberarepresentedinbold.First,abaselinemodel(A9)wasselected,combiningtheWav2Vec2featureextractorwiththeAASISTclassifier.TheA9modelwasthenfine-tunedusingtheRIR-TimeMaskmethodtoobtainthebest-augmentedmodel(B5),whichwassubse-quentlyfurtherfine-tunedusingaGAM-basedco-enhancementstrategy.Finally,thelogitsscoresfromtheC11andC12modelswerefusedusinganaveragescore-levelfusionmethod,andtheresultsweresubmittedforevaluationontheCodalabplatform.whichisdedicatedtospoofing-robustautomaticspeakerverifi-cation.Undertheclosedconditions,participantsarerestrictedfromusingspecifieddataprotocols.Conversely,theopencon-ditionsoffergreaterflexibility,allowingparticipantstoutilizeexternaldataandpre-trainedself-supervisedmodels,providedthereisnooverlapbetweentrainingdata(i.e.,thatusedfortrainingfoundationalmodels)andevaluationdata.Track1issimilartotheDFtrackoftheASVspoof2021Challenge,re-flectingascenarioinwhichanattackerhasaccesstoatargetedvictim’svoicedata,suchasdatapostedonsocialmedia.Inthisscenario,theevaluationsetcontaineddataprocessedwithcon-ventionalcodecsormodernneuralcodecs.Track2,similartotheLAsub-taskfrompreviousASVspoofchallenges,ispred-
65

icatedonatelephonyscenariowheresyntheticandconvertedspeechisdirectlyinjectedintoacommunicationsystemwith-outanyacousticpropagation.TheASVspoof5Challengeintroducessignificantchangesinsourcedata,attacktypes,andevaluationmetrics.Thesourcedata,extractedfromtheMultilingualLibrispeechEnglishparti-tion[11],includesavastlygreaternumberofspeakersthanpre-viousASVspoofdatabases.Notably,thespoofingattacksinthetraining,development,andevaluationsetsareentirelydisjoint.AsshowninTable1,thetrainingdatasetisusedtoadjustmodelparameters,whilethedevelopmentdatasetisusedtotuneandevaluateperformance.Theprogresssetinitiallyassessesthedetectionmodel’sperformance,allowingparticipantsuptofoursubmissionsperdayviatheCodalabplatform.Theevaluationsettestsitsgeneralizability,withonlyonesubmissionallowedperteam.Newevaluationmetrics,minDCF[12]forTrack1andagnosticDCF[13]forTrack2,havebeenintroducedtobetterassessanti-spoofingsystems.ThispaperpresentstheSZU-AFSanti-spoofingsystemforTrack1underopenconditions.ItsdesigndiagramisillustratedinFigure1,wheremodelIDsarelabeledfromAtoD,withnumbersindicatingtheirrespectiveversions.Thissystemhasfourstages:baselinemodelselection,explorationofeffectivedataaugmentation(DA)methodsforfine-tuning,applicationofaco-enhancementstrategyutilizinggradientnormawaremin-imization(GAM)forsecondaryfine-tuning,andfusionoflog-itsscoresfromthetwotop-performingmodels.Specifically,comparativeexperimentalanalysiswasconductedfirstbycom-biningthreepre-trainedmodelswiththreedistinctclassifierstoselectanappropriatebaselinemodel.Wehaveselectedthepre-trainedWav2Vec2model[14]asthefeatureextractor,cou-pledwiththeAASISTclassifier[15],toserveasthebaselinemodel(A9).Secondly,wehaveproposedthreeDApoliciestoexploretheeffectivenessofvariousDAmethods:single-DA,random-DA,andcascade-DA.Thebest-performingmodelistheonefine-tunedbyaugmenteddatageneratedbysequen-tiallyapplyingroomimpulseresponse(RIR)noiseandtimemasking(TimeMask)method,resultinginanaugmentedmodel(B5).Next,weemployedaGAM-basedco-enhancementstrat-egytoconsiderdataandoptimizersimultaneouslytoenhancemodelgeneralizability.Withthisstrategy,theB5modelhasbeenfine-tunedbycombiningvariousDAmethodswiththeGAMmethod,resultingintheC11andC12modelsasthetwobest-performingfine-tunedmodels.Finally,wehavefusedthepredictedlogitsscoresfromtheC11andC12modelsusinganaveragescore-levelfusionmethodtogeneratefinalevaluationscores,constitutingsystemD4.Thispaperisorganizedasfollows:Section2elaboratesthecoremodulesoftheSZU-AFSsystem,includingthebaselinemodel,thethreeDApolicies,theGAM-basedco-enhancementstrategy,andthescore-levelfusion.Implementationdetailsre-gardingthedatasetinformationandmodelhyperparametersareprovidedinSection3.Section4providesexperimentalresultsandanalysis.ConclusionsaredrawninSection5.2.MethodologyTheSZU-AFSanti-spoofingsystemconsistsoffourstagesde-tailedinseparatesubsections:baselinemodel,dataaugmen-tation,gradientnormawareminimization(GAM)-basedco-enhancementstrategy,andscore-levelfusion.Notethatwetrainedtendifferentbaselinemodels,sixaugmentedmodels,andeightmodelsusingvariousDAandGAMmethods.ModelIDsarelabeledAtoD,andnumbersindicateversions.2.1.BaselineModel2.1.1.Front-endfeatureextractorGiventheurgentneedtoimprovethegeneralizabilityofspoof-ingdetectionsystems,speechself-supervisedmodelshavegainedincreasingattention.Priorresearchshowsthatusingspeechself-supervisedmodelsasthefront-endfeatureextrac-torsandtheback-endclassifier,cansubstantiallyimprovethegeneralizationofspoofingdetectionmodels[16,17,18,19].Wehaveusedtheself-supervisedWavLM-Base1[20],HuBERT-Base2[21],andWav2Vec2-Large3[14]asfront-endfeatureextractorsinsteadofconventionalhandcraftedacous-ticfeatures,suchaslinearfrequencycepstralcoefficientsandmel-spectrograms.Theself-supervisedlearningmodelsextractspeechrepresentationsorembeddingsfromtherawwaveform.2.1.2.Back-endclassifierTheback-endclassifiersofthelatestspoofingdetectionsystemsmainlyadoptdeeplearningmethods[22,23,24],significantlyoutperformingtraditionalclassifierssuchassupportvectorma-chineandGaussianmixturemodel[25,26].Wehavetriedthreerepresentativeclassifierscombinedwithfront-endpre-trainedmodels,detailedasfollows:•Fullyconnected(FC)classifier[22]:Thisclassifiercombinesaglobalaveragepoolinglayer,followedbyaneuralnetworkwiththreefullyconnectedlayersem-ployingLeakyReLUactivationfunctions.Itendswithalinearoutputlayerforbinaryclassification.•Conformerclassifier[23]:ThisclassifiercombinesaconvolutionalneuralnetworkandaTransformernetworkforspoofingdetection.Itcomprisesfourblocks,eachwithfourattentionheadsandakernelsizeof31,totaling2.4millionparameters.•AASISTclassifier[24]:ThisclassifiercombinesaRawNet2-basedencoder[27]andagraphnetworkmod-ule.Specifically,itremovestheSincconvolutionallayer-basedfront-endfromtheRawNet2-basedencoder.2.1.3.ModelselectionAsshowninTable2,wehaveevaluatedthedetectionperfor-manceoftheA1-A10modelsusingthedevelopmentsetofASVspoof5.TheA1-A9modelsarecombinationsofthreepre-trainedmodelswiththreedifferentclassifiers,whiletheA10modelcombinestheWav2Vec2pre-trainedmodelwithallclas-sifiers,generatingpredictivescoresbyprocessingconcatenatedfeaturesthroughalinearlayer.Accordingtoexperimentalre-sults,wehaveselectedtheA9modelasthebaselinebyutiliz-ingaWav2Vec2-basedfront-endfeatureextractorpairedwithanAASIST-basedback-endclassifier.2.2.PrimaryFine-tuningwithDataAugmentationToenhancethegeneralizationperformance,wehaveconductedexperimentswiththreeDApolicies:single-DA,random-DA,andcascade-DA,tofine-tunethebaselinemodel.ThethreeDApolicies,asdepictedinFigure2,aredetailedasfollows.1https://github.com/microsoft/unilm/blob/master/wavlm2https://github.com/facebookresearch/fairseq/tree/main/examples/hubert3https://github.com/facebookresearch/fairseq/tree/main/examples/wav2vec
66

Figure2:IllustrationofthethreedifferentDApolicies.ToenhancethegeneralizationabilitiesoftheA9model,weex-perimentwiththreedistinctDApolicies,includingsingle-DA,random-DA,andcascade-DA.2.2.1.Single-DApolicyAspecificDAmethodisappliedtoalloriginaltrainingdataforthesingle-DApolicy.ThedetailsoftheDAmethodsemployedaredescribedbelow:•RIR4:Theroomimpulseresponse(RIR)capturestheacousticcharacteristicsofaroomoranenvironment.AnoiseclipisrandomlyselectedfromtheRIRdatabaseandsuperimposedontotheoriginaltrainingspeech,withtheintensityrandomlyvaryingbetween20%and80%.•RawBoost[28]:RawBoostincorporates3distincttypesofnoise:linearandnon-linearconvolutive(LnL)noise,stationarysignal-independentadditive(SSI)noise,andimpulsivesignal-dependentadditive(ISD)noise.•Signalcompanding:Thea-lawandµ-lawaresignalcompandingmethodsdevelopedtoenablethetransmis-sionofsignalswithalargedynamicrangethroughsys-temswithlimiteddynamicrangecapabilities.Duringtheenhancementoftheinputspeech,eithera-laworµ-lawisrandomlyselected.•TimeMask:Fortheinputspeech,consecutivetimestepsfromt0tot0+taresettozero.Thedurationtisuni-formlyselectedfrom0toT,andthestartingpointt0israndomlychosenfromtheinterval[0,τ−t).Here,τrepresentsthetotalnumberoftimesteps,andTvariesrandomlybetween20%and50%ofτ.•Mixup[29]:Mixupregularizationinvolvestrainingthemodelusingasetofmixedspeechutterancesandlabels,ratherthantheoriginaltrainingdata,withtheinterpo-lationparametersampledfromasymmetricBeta(σ,σ)distribution,whereσ=1.0.•Amplitude:Amplitudeenhancementinvolvesselectingtwospeechutterancesfromthesamespeakerandlabel,mixingtheiramplitudespectrawithacertainprobability,andthenapplyinginverseFouriertransformationwiththecorrespondingphasespectratoobtaintheenhancedutterances.2.2.2.Random-DApolicyUnlikeasingle-DAstrategy,therandom-DApolicyinvolvesrandomlyselectinganaugmentationmethodfromaDAsetforeachutteranceoftheoriginaltrainingdata.Morespecifically,weusedthreeDAsets:•Noiseset:Thissetcontains3noise-basedDAmethodsfromtheaudiomentations5library,withcorresponding4https://www.openslr.org/28/5https://github.com/iver56/audiomentationsmodulesnamedAddColorNoise,AddGaussianNoise,andAddGaussianSNR.•Filterset:Thissetcontains7filter-basedDAmethodsfromtheaudiomentationslibrary,withcorrespondingmodulesnamedBandPassFilter,BandStopFilter,High-PassFilter,HighShelfFilter,LowPassFilter,LowShelf-Filter,andPeakingFilter.•Mixset:Thissetcontains13DAmethodsofmixedtypesfromtheaudiomentationslibrary,withcorrespond-ingmodulesnamedAddGaussianNoise,AirAbsorption,Aliasing,BandPassFilter,Shift,PitchShift,HighPass-Filter,LowPassFilter,PolarityInversion,PeakingFilter,TimeStretch,TimeMask,andTanhDistortion.2.2.3.Cascade-DApolicyThecascade-DApolicyencouragesselectingtwoormoreDAmethodsinasequentialcascademannertoenhancetheoriginaltrainingdataprogressively.Threetypesofcascade-DAmethodsaregivenbelow:•RIR-TimeMask:RIR-TimeMaskconsistsofatwo-levelcascadeofDAmethods,sequentiallyaddingRIRnoiseandTimeMaskmethodtotheoriginaltrainingdata.•LnL-ISD:LnL-ISDconsistsofatwo-levelcascadeofDAmethods,sequentiallyaddingLnLandISDnoisetotheoriginaltrainingdata.BothLnLnoiseandISDnoisearederivedfromtheRawBoostmethod.•Noise-Filter:Noise-Filterconsistsofatwo-levelcas-cadeofDAsets,sequentiallyapplyingonemethodran-domlyselectedfromthenoisesetandanotherfromthefiltersettoenhancetheoriginaltrainingdata.NotethattheRIRTimeMaskmethodisusedintheprimaryfine-tuningstage,whileLnL-ISD,Noise-Filter,andcombina-tionsofcascade-DAmethodsareusedinthesecondaryfine-tuningstage.2.2.4.ModelselectionTheA9modelisfine-tunedusingonlytheon-the-flyaugmenteddata.Wehaveevaluatedthedetectionperformanceofsixmod-els(B1-B6,whichareshowninTable3)withdifferentDAmethods,usingtheprogresssetofASVspoof5.Specifically,wehavefine-tunedtheA9modelusingdistinctDAmethods,in-cludingAmplitude,a-laworµ-law,Mix,andRIR-TimeMask.TheB4-B6modelssharethesameaugmentationmethodsbutvaryinthenumberofinputspeechsamplesusedfortraining:64,600,96,000,and128,000,respectively.Followingexperi-mentalanalysis,theB5modelhasbeenchosenforfurtherin-vestigation.2.3.SecondaryFine-tuningwithGAM-basedCo-enhancementStrategyUnlikeDAmethods,whichfocusonincreasingthediversityoftrainingdata,theGAMmethodisanoptimizationapproachforenhancingmodelgeneralization.Toalleviatethisissue,thefine-tuningprocesshasbeendividedintotwostages:aprimarystagewithoutGAM,asdescribedintheprevioussubsection,andasecondarystagewithDAandGAMco-enhancement,asillustratedinthissubsection.2.3.1.GradientnormawareminimizationSharpness-awareminimization(SAM)[30]anditsvariants[31]arerepresentativetrainingalgorithmstoseekflatminimafor
67

bettergeneralization.Shimetal.[32]employedSAManditsvariantsinspoofingdetection,improvingmodelgeneralization.Inspiredbythis,weexploitarecentlyproposedoptimizationmethod,gradientnormawareminimization(GAM)[33].GAMseeksflatminimawithuniformlysmallcurvatureacrossalldirectionsintheparameterspace.Specifically,itimprovesthegeneralizationofmodelstrainedwiththeAdamoptimizerbyoptimizingfirst-orderflatness,whichcontrolsthemaximumgradientnormintheneighborhoodofminima.Letθ∈Θ⊆RddenotetheparametersoftheB5model.TheAdamoptimizeristhendescribedasfollows:θt+1=θt−ηgt,(1)wheretisthetimestep,ηisthelearningrate,andgtisthelossgradient.Forthefirst-orderflatnessR1ρ(θ),itcouldbecom-putedby:R1ρ(θ)≜ρ·maxθ′∈B(θ,ρ)∥∇ˆL(θ′)∥,(2)whereˆL(θ)=(cid:80)ni=1ℓ(θ,xi,yi)denotestheempiricallossfunction,xiandyidenotethei-thspeechsampleanditscor-respondinglabel,respectively.ρ>0istheperturbationradiusthatcontrolsthemagnitudeoftheneighborhood,andB(θ,ρ)denotestheopenballofradiusρcenteredattheparameterθintheEuclideanspace.Fordetailedderivation,seeAppendixAof[33].ThekeytooptimizinggeneralizationerrorwithGAMiscontrollingthelossfunctionˆL(θ)andfirst-orderflatnessR1ρ(θ).ThepseudocodeofthewholeoptimizationprocedureisshowninAlgorithm1.Algorithm1GradientnormAwareMinimization(GAM)Input:Batchsizeb,learningrateηt,perturbationradiusρt,trade-offcoefficientα,smallconstantξ1:t←0,θ0←initialparameters2:whileθtnotconvergeddo3:SampleWtfromthetrainingdatawithbinstances4:Calculatetheempiricallossgradient∇ˆL(θt):hlosst←∇ˆL(θt)5:Calculatetheperturbedgradientusingthelossgradient∇ˆLWt(θt)ofthesampleWtandtheHessianmatrix∇2ˆLWt(θt):ft←∇2ˆLWt(θt)·∇ˆLWt(θt)∥∇ˆLWt(θt)∥+ξ6:Calculatetheadversarialparametersadjustedviatheper-turbedgradient:θadvt←θt+ρt·ft∥ft∥+ξ7:Calculatethenormgradient∇R(1)ρt(θt):hnormt←ρt·∇2ˆLWt(θadvt)·∇ˆLWt(θadvt)∥∇ˆLWt(θadvt)∥+ξ8:θt+1←θt−ηt(hlosst+αhnormt)9:t←t+110:endwhile11:returnθt.2.3.2.Co-enhancementstrategyTheGAM-basedco-enhancementstrategyinvolvesdataaug-mentationoftheinputspeechandcombinestheGAMmethodwiththeAdamoptimizertofurtherfine-tunetheDA-augmentedbaselinemodel(B5).Unliketheprimaryfine-tuningwithDAmethods,thisstrategyhasexploredmoreefficienttwo-levelandthree-levelDAmethods,combinedwithRIRorTimeMask,toprocesstheoriginaltrainingdata.Specifically,wehavecom-binedeightdifferentDAmethodswithGAM:C1(RIR),C2Table1:SummaryofASVspoof5Track1database.“Spr.”de-notesthenumberofspeakers,while“Train.”,“Dev.”,“Prog.”,“Eval.”refertothetraining,development,progress,andevalu-ationsets,respectively.SetsSpr.AttackTypesUtterancesBonafideSpoofedTotalTrain.400A1-A818,797163,560182,357Dev.785A9-A1631,334109,616140,950Prog.————40,765Eval.737A17-A32395,924138,688680,774(a-laworµ-law),C3andC4(Mix),C5andC6(LnL-ISD),C7(RIR+Mix),C8andC9(RIR-TimeMask),C10andC11(RIR-TimeMask+Mixup),andC12(RIR+Noise-Filter).AsshowninTable4,wehaveevaluatedthedetectionperformanceofmodelsC1-C12usingtheprogresssetofASVspoof5.Ex-perimentalanalysisindicatesthattheC11andC12modelsarethetwobest-performingmodelsintermsofminDCF.2.4.Score-levelFusionTheindividualmodelscoreshavebeendirectlyoutputaslogitsfromthelinearlayerwithoutapplyingmin-maxnormalization.Buildingonthis,wehaveutilizedanaveragescore-levelfusionmethod,wherethepredictedscoresfromeachmodelhavebeensummedandaveragedtodeterminethefinalpredictionscore.AsshowninTable5,wehaveevaluatedthedetectionper-formanceoffusedmodelsD1-D4oneithertheprogressoreval-uationsetsofASVspoof5.Specifically,wehavetestedfourfusedmodels:D1(B4+B5),D2(B1toB6),D3(C8+C9),andD4(C11+C12).Amongthesemodels,wehaveselectedthebest-performingfusedsystem,D4,forsubmissiontotheevalu-ationphase.3.ExperimentalSetup3.1.DatasetsandMetrics3.1.1.DatasetsThispaperfocusesontheTrack1stand-alonespeechdeepfakedetectiontaskofASVspoof5,withasummaryoftheTrack1databaseprovidedinTable1.Thedatasetcontains1,044,846utterances,eachencodedasa16kHz,16-bitFLACfile.Thetraininganddevelopmentsetseachcontainspoofedspeechgen-eratedby8differenttext-to-speech(TTS)orvoiceconversion(VC)methods.Incontrast,theevaluationsetincludesspoofedspeechfrom16diverseattackmethods,includingTTS,VC,and,forthefirsttime,adversarialattacks.Theevaluationsetcontainsmorethantwicethenumberofsamplesasthecom-binedtraininganddevelopmentsets,makingdetectionsignifi-cantlymorechallenging.Notably,theprogresssetisasubsetoftheevaluationset.3.1.2.MetricsDifferentfrompreviousASVspoofchallenges,ASVspoof5ChallengeusestheminDCFastheprimarymetricforthecom-parisonofspoofingcountermeasures,withthecostoflog-likelihoodratio(Cllr)[34]andtheequalerrorrate(EER)asasecondarymetrics.Accuracy(ACC)wasintroducedtoevalu-atethedetectionmodel’sperformanceonthedevelopmentset.Incontrast,EERprovidesamoresuitablemeasureofperfor-
68

Table2:PerformanceinAccuracy(%)andEER(%)ofdiffer-entbaselinemodelsontheTrack1developmentset.Thehigh-lightedmodelwasselectedforfurtherfine-tuningtoenhanceitsgeneralizability.ModelIDFeatureExtractorBack-endClassifierAccuracy(%)EER(%)A1WavLMFC54.5640.00A2Conformer67.8043.50A3AASIST77.2542.70A4HuBERTFC73.1219.43A5Conformer78.319.56A6AASIST81.587.81A7Wav2Vec2FC91.492.17A8Conformer81.816.50A9AASIST87.641.55A10FC+AASIST+Conformer88.562.04mancewhenthedataislimitedorimbalanced.Thus,EERisbettersuitedthanACCforevaluatingspoofdetectionmodels.Thenormaliseddetectioncostfunction(DCF)is:DCF(τcm)=β·Pcmmiss(τcm)+Pcmfa(τcm),β=CmissCfa·1−πspfπspf,(3)whereτcmisthedetectionthreshold,πspfisassertedpriorprob-abilityofspoofingattack,andCmissandCfaarethecostsofamissandafalsealarm,respectively.ThefollowingparameterswereusedfortheASVspoof5challengeevaluation:Cmiss=1,Cfa=10,πspf=0.05,andβ≈1.90.ThenormalizedDCFin(3)isusedtocomputetheminimumDCF,definedasminDCF=minτcmDCF(τcm).3.2.TrainingDetailsInourexperiments,thefollowingparameterswerekeptcon-sistent.WeusedtheAdamoptimizer(β1=0.9,β2=0.999,ϵ=10−8)[35],withaninitiallearningrateof5×10−6,controlledbyacosineannealingschedulerwithaminimumlearningrateof1×10−8,andamaximumof100trainingepochs.Thetrainingwasconductedusingconventionalcross-entropyloss,withearlystoppingappliedifthedevelopmentsetlossdidnotimprovewithintenepochs.AllexperimentswereexecutedontwoNVIDIAA100GPUs.ThetrainingepochsforthemodelsusedtoobtaintheD4systemwereasfollows:12epochs(A9),4epochs(B5),2epochs(C11),and5epochs(C12).ThetrainingtimerequiredforthecombinedDAandGAMmethodisapproximatelythreetimesthatoftheregu-larDAmethodalone.Theresultstablehighlightsthebest-performingvaluesinboldforeachcolumn.4.ResultsandAnalysis4.1.ComparisonAnalysisofDifferentBaselineModelsWeintegratedthreepre-trainedmodelswiththreeclassifierstoassessthenecessityofdifferentbaselinemodels,testingtheirperformanceontheTrack1developmentset.Thetraininganddevelopmentdataweretruncatedorpaddedto64,600samplepointstoaccommodateGPUmemoryconstraints.TheaccuracyandEERfordifferentbaselinemodelsarere-portedinTable2.AsindicatedinTable2,weobserve:•Amongthedifferentfeatureextractors,Wav2Vec2-baseddetectionmodels(e.g.,A7,A8,A9,andA10)achievedhigheraccuracyandlowerEER,whichindicatestheirbettereffectivenessthanWavLM-basedandHuBERT-baseddetectionmodels.ThisresultisduetothefactthatboththeWavLMandHuBERTpre-trainedmodelsusethebaseversion,whichcontainsfewerthanone-thirdofthelearnableparametersintheWav2Vec2-Largemodel.•Amongthedifferentclassifiers,AASISTprovedtobemorecompetitivethanothers(e.g.,FCandConformer)whenpairedwithvariousfeatureextractors,furthercon-firmingitsexcellentperformanceinspeechspoofingde-tection.Furthermore,leveragingtheWav2Vec2featureextractor,weconcatenatedthefinalpredictiveoutputsfromthreeclassifiersforclassification.However,theA10model’sresultsfellbetweentheindividualclassi-fiers’results,providingnoimprovement.Thus,usingonlythebestclassifierissufficient.•WhiletheA9model’saccuracyisslightlylowerat87%comparedtotheA7andA10models,itachievesthelow-estEERat1.55%.OwingtoitsoutstandingEERperfor-mance,theA9modelhasbeenselectedforfurtherex-perimentalexploration.4.2.ComparisonAnalysisofDifferentDATable3showstheeffectivenessofvariousDAmethodsduringtheprogressphaseofTrack1.ComparedwiththeB1andB3models,theB2andB4modelsachievedlowerminDCFandEER.TheA9modelpresentssuperiordetectionperformancewhenfine-tunedwithsignalcompression(a-laworµ-law),RIRnoise,andTimeMask.However,theB4modelexhibitedahigherCllr.TheB5modeloutperformsallothermodelsintermsofminDCF,Cllr,andEERat0.043,0.235,and1.5%,re-spectively.Owingtoitsoutstandingperformance,theB5modelhasbeenselectedastheaugmentedmodelforfurtherexperi-mentalexploration.AlthoughcurrentexperimentalresultsdonotconclusivelydeterminewhichofthethreedifferentDApoliciesismostef-fective.Werecommendprioritizingexperimentalexplorationunderrandom-DAandcascade-DApoliciesforspeechspoof-ingdetectiontasks.4.3.EffectofGAM-basedCo-enhancementStrategyWiththeB5model’sgoodresults,wealsoinvestigatewhetherthespoofingdetectionperformancecanbefurtherimprovedbyusingtheGAMmethod.Table4showstheperformanceofvar-iousDAmethodsandGAMmethodontheTrack1progressphase.Fortheeffectofdataaugmentation,theC1andC2mod-elsdidnotsignificantlyimproveminDCFandEERovertheB5modelintheprogressphase.Specifically,theB5modelusingRIR-TimeMask(C8andC9models)anditscombinationwiththeMixup(C10andC11models)outperformedtheC2andC3modelsacrossmostmetrics,indicatingthatmorecomplexaug-mentationcanbelearningmorerobustfeatures.Inaddition,thecomparisonamongmodelsfromC8toC11showsthattheMixupmethodsignificantlyimprovesbothminDCFandEER,whichsuggeststhatitcontributestotheimprovement’sgeneral-izability.TheGAMmethod,particularlyinB5andC9models,improvedminDCFandEER,effectivelyenhancingmodelgen-eralizability.Theexperimentalresultsdemonstratetheimpor-tanceofselectingappropriatedataaugmentationandoptimiza-tiontechniquestoenhancespoofingdetectionperformance.
69

Table3:EffectofA9modelwithvariousDAmethodsonTrack1progressphase.Thehighlightedmodelwasselectedforfurtherfine-tuningtoenhanceitsgeneralizability.ModelIDDAPolicyDAMethodOptimizerSamplePointsofTrainingSamplePointsofProgressminDCFactDCFCllrEERB1SingleAmplitudeAdam64,60064,6000.1370.3220.4666.76B2Randoma-laworµ-law64,60064,6000.0630.1080.2872.32B3RandomMix64,60064,6000.1390.4540.5536.21B4CascadeRIR-TimeMask64,60064,6000.0570.4201.5082.05B5CascadeRIR-TimeMask96,00096,0000.0430.1160.2351.50B6CascadeRIR-TimeMask128,000128,0000.0670.1430.3022.46Table4:EffectoftheB5modelunderGAM-basedco-enhancementstrategyonTrack1progressphase.ModelIDDAPolicyDAMethodOptimizerSamplePointsofTrainingSamplePointsofProgressminDCFactDCFCllrEERC1SingleRIRAdam+GAM64,60096,0000.0580.0620.1112.07C2Randoma-laworµ-law96,0000.0460.0670.2041.63C3RandomMix64,6000.0640.3220.6612.26C496,0000.0500.1940.3651.79C5CascadeLnL-ISD64,6000.0570.2300.3672.06C696,0000.0480.1550.2571.71C7CascadeRIR+Mix96,0000.0460.1490.2211.63C8CascadeRIR-TimeMask64,6000.0510.1890.3141.84C996,0000.0410.1900.2761.48C10CascadeRIR-TimeMask+Mixup64,6000.0500.9221.6881.77C1196,0000.0380.8401.3341.39C12CascadeRIR+Noise-Filter96,0000.0350.0870.1081.30Table5:Theperformanceofdifferentfusedsystemswasevalu-atedontheASVspoof5Track1database.“Prog.”and“Eval.”refertotheprogressandevaluationsets,respectively.PhaseIDSystemminDCFactDCFCllrEERProg.D1B4+B50.0390.3070.6351.33D2B1∼B60.0370.1670.3051.31D3C8+C90.0400.6330.4561.41D4C11+C120.0270.2690.3660.99Eval.D4C11+C120.1150.5730.9564.044.4.ComparisonAnalysisofDifferentFusedSystemsTable5showstheperformanceofthefourfusedsystemsoneithertheprogressorevaluationsetsofASVspoof5.Weob-servedthatscore-levelaveragefusionenhancesmodelperfor-mancecomparedtoindividualdetectionmodels,particularlyinminDCFandEERmetrics.FusingC11andC12models(D4)resultedinoptimalprogressphaseperformance,achiev-ingaminDCFof0.027andanEERof0.99%.However,theD4systemexhibitedasignificantperformancediscrepancybe-tweentheprogressandevaluationphases,highlightingthechal-lengingnatureoftheevaluationset.4.5.ImpactofDifferentSamplePointsTable3alsoshowsacomparisonintermsofsamplepointsforthemodeltraining.Using96,000samplepointsofinputspeech,theB5modelachievedaloweractDCFandCllrthanB4andB6.TheB6modelexhibitedpoorperformance,indicatingthatincreasingthenumberoftrainingsamplesdoesnotnecessarilyenhancethemodel’sdetectioncapabilities.Infact,inputtingmoresamplepointsfortrainingmayreducethemodel’sgener-alizationability.Optimizingtrainingwithanappropriatenum-berofsamplepointsismorebeneficialforimprovingdetectionperformancethansimplyincreasingtheamountoftrainingdata.TheresultspresentedinTable4revealthatwhenthemodelwastrainedusinginputspeechwith64,600samplepoints,asignificantperformanceimprovementwasobservedduringtheinferencestagewhenutilizinginputspeechwith96,000samplepoints.Thisphenomenonmaybeassociatedwiththedifferentutterancedurationdistributionintheprogressset.Morestudiesarerequiredtoverifythisrelationshipfurtherandanalyzeit.5.ConclusionThispaperdescribestheSZU-AFSsystemforTrack1oftheASVspoof5Challengeunderopenconditions.Insteadoffocus-ingonvariouspre-trainedfeaturefusionandcomplexscorefu-sionmethods,weusedDAandGAMenhancementstrategiestoimprovespoofingdetectiongeneralization.Thefinalbestfusedsystemsubmittedachieved0.115minDCFand4.04%EERontheASVspoof5challengeevaluationset.Theexperimentsproducedafewvaluablefindings.First,applyingtheRIR-TimeMaskmethodfordataaugmentationhasprovenmoreeffective.Buildingonthis,employingacascade-DAstrategycanfurtherimprovemodelperformance.Second,theGAMmethodsignificantlyimprovesmodelgeneralizationwhencombinedwiththeAdamoptimizeronbothprogressandevaluationsetsdespitethelengthytrainingtimerequired.Duetotimeconstraints,themodelwasfine-tunedintwostages.Us-ingtheGAMmethodthroughouttheentireprocessmighthaveproducedbetterresults.
70

6.AcknowledgmentsWewouldliketothanktheorganizersforhostingtheASVspoof5Challenge.ThisworkwassupportedinpartbyNSFC(GrantU23B2022,U22B2047)andGuangdongProvincialKeyLabo-ratory(Grant2023B1212060076).7.References[1]ZhizhengWu,NicholasEvans,TomiKinnunen,JunichiYamagishi,FedericoAlegre,andHaizhouLi,“Spoofingandcountermeasuresforspeakerverification:Asurvey,”SpeechCommunication,vol.66,pp.130–153,2015.[2]ZhizhengWu,TomiKinnunen,NicholasW.D.Evans,JunichiYamagishi,CemalHanilc¸i,Md.Sahidullah,andAleksandrSizov,“ASVspoof2015:thefirstautomaticspeakerverificationspoofingandcountermeasureschal-lenge,”inProc.Interspeech,2015,pp.2037–2041.[3]TomiKinnunen,Md.Sahidullah,H´ectorDelgado,Massi-milianoTodisco,NicholasW.D.Evans,JunichiYamag-ishi,andKong-AikLee,“TheASVspoof2017challenge:Assessingthelimitsofreplayspoofingattackdetection,”inProc.Interspeech,2017,pp.2–6.[4]MassimilianoTodisco,XinWang,VilleVestman,Md.Sahidullah,H´ectorDelgado,AndreasNautsch,JunichiYamagishi,NicholasW.D.Evans,TomiH.Kinnunen,andKongAikLee,“ASVspoof2019:Futurehorizonsinspoofedandfakeaudiodetection,”inProc.Interspeech,2019,pp.1008–1012.[5]JunichiYamagishi,XinWang,MassimilianoTodisco,MdSahidullah,JosePatino,AndreasNautsch,XuechenLiu,KongAikLee,TomiKinnunen,NicholasEvans,etal.,“ASVspoof2021:acceleratingprogressinspoofedanddeepfakespeechdetection,”inProc.ASVspoofChal-lengeWorkshop,2021,pp.47–54.[6]XinWang,H´ectorDelgado,HemlataTak,Jee-weonJung,Hye-jinShim,MassimilianoTodisco,IvanKukanov,XuechenLiu,MdSahidullah,TomiKinnunen,NicholasEvans,KongAikLee,andJunichiYamagishi,“ASVspoof5:Crowdsourcedspeechdata,deepfakes,andadversarialattacksatscale,”inASVspoofWorkshop2024(accepted),2024.[7]TianxiangChen,AvroshKumar,ParavNagarsheth,GaneshSivaraman,andElieKhoury,“Generalizationofaudiodeepfakedetection,”inProc.Odyssey,2020,pp.132–137.[8]Jo˜aoMonteiro,JahangirAlam,andTiagoH.Falk,“Gen-eralizedend-to-enddetectionofspoofingattackstoau-tomaticspeakerrecognizers,”ComputerSpeech&Lan-guage,vol.63,pp.101096,2020.[9]XinWangandJunichiYamagishi,“Acomparativestudyonrecentneuralspoofingcountermeasuresforsyntheticspeechdetection,”inProc.Interspeech,2021,pp.4259–4263.[10]YouZhang,FeiJiang,andZhiyaoDuan,“One-classlearn-ingtowardssyntheticvoicespoofingdetection,”IEEESig-nalProcessingLetters,vol.28,pp.937–941,2021.[11]VineelPratap,QiantongXu,AnuroopSriram,GabrielSynnaeve,andRonanCollobert,“MLS:Alarge-scalemultilingualdatasetforspeechresearch,”inProc.Inter-speech,2020,pp.2757–2761.[12]SeyedOmidSadjadi,CraigSGreenberg,ElliotSinger,DouglasAReynolds,andLisaMason,“NIST2020CTSspeakerrecognitionchallengeevaluationplan,”2020.[13]Hye-jinShim,Jee-weonJung,TomiKinnunen,NicholasW.D.Evans,Jean-Franc¸oisBonastre,andItshakLapidot,“a-DCF:anarchitectureagnosticmetricwithapplicationtospoofing-robustspeakerverification,”inProc.Odyssey,2024,pp.158–164.[14]AlexeiBaevski,YuhaoZhou,AbdelrahmanMohamed,andMichaelAuli,“Wav2vec2.0:Aframeworkforself-supervisedlearningofspeechrepresentations,”inProc.NIPS,2020,vol.33,pp.12449–12460.[15]Jee-weonJung,Hee-SooHeo,HemlataTak,Hye-jinShim,JoonSonChung,Bong-JinLee,Ha-JinYu,andNicholasW.D.Evans,“AASIST:audioanti-spoofingus-ingintegratedspectro-temporalgraphattentionnetworks,”inProc.ICASSP,2022,pp.6367–6371.[16]JuanM.Mart´ın-Do˜nasandAitor´Alvarez,“Thevi-comtechaudiodeepfakedetectionsystembasedonwav2vec2forthe2022ADDchallenge,”inProc.ICASSP,2022,pp.9241–9245.[17]JinWooLee,EungbeomKim,JunghyunKoo,andKyoguLee,“Representationselectiveself-distillationandwav2vec2.0featureexplorationforspoof-awarespeakerverification,”inProc.Interspeech,2022,pp.2898–2902.[18]JiafengZhong,BinLi,andJiangyanYi,“Enhancingpar-tiallyspoofedaudiolocalizationwithboundary-awareat-tentionmechanism,”arXivpreprintarXiv:2407.21611,2024.[19]YujieYang,HaochenQin,HangZhou,ChengchengWang,TianyuGuo,KaiHan,andYunheWang,“Arobustaudiodeepfakedetectionsystemviamulti-viewfeature,”inProc.ICASSP,2024,pp.13131–13135.[20]SanyuanChen,ChengyiWang,ZhengyangChen,YuWu,ShujieLiu,ZhuoChen,JinyuLi,NaoyukiKanda,TakuyaYoshioka,XiongXiao,JianWu,LongZhou,ShuoRen,YanminQian,YaoQian,JianWu,MichaelZeng,Xi-angzhanYu,andFuruWei,“WavLM:Large-scaleself-supervisedpre-trainingforfullstackspeechprocessing,”IEEEJournalofSelectedTopicsinSignalProcessing,vol.16,no.6,pp.1505–1518,2022.[21]Wei-NingHsu,BenjaminBolte,Yao-HungHubertTsai,KushalLakhotia,RuslanSalakhutdinov,andAbdelrah-manMohamed,“HuBERT:Self-supervisedspeechrepre-sentationlearningbymaskedpredictionofhiddenunits,”IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,vol.29,pp.3451–3460,2021.[22]XinWangandJunichiYamagishi,“Spoofedtrainingdataforspeechspoofingcountermeasurecanbeefficientlycre-atedusingneuralvocoders,”inProc.ICASSP,2023,pp.1–5.[23]ErosRosello,AlejandroG´omezAlan´ıs,AngelM.Gomez,andAntonioM.Peinado,“Aconformer-basedclassifierforvariable-lengthutteranceprocessinginanti-spoofing,”inProc.Interspeech,2023,pp.5281–5285.[24]HemlataTak,MassimilianoTodisco,XinWang,Jee-weonJung,JunichiYamagishi,andNicholasW.D.Evans,“Au-tomaticspeakerverificationspoofinganddeepfakedetec-tionusingwav2vec2.0anddataaugmentation,”inProc.Odyssey,2022,pp.112–119.
71

[25]JiangyanYi,ChenglongWang,JianhuaTao,XiaohuiZhang,ChuYuanZhang,andYanZhao,“Audiodeepfakedetection:Asurvey,”arXivpreprintarXiv:2308.14970,2023.[26]YuxiongXu,BinLi,ShunquanTan,andJiwuHuang,“Researchprogressonspeechdeepfakeanditsdetectiontechniques,”JournalofImageandGraphics,vol.29,no.08,pp.2236–2268,2024.[27]HemlataTak,JosePatino,MassimilianoTodisco,AndreasNautsch,NicholasEvans,andAnthonyLarcher,“End-to-endanti-spoofingwithrawnet2,”inProc.ICASSP,2021,pp.6369–6373.[28]HemlataTak,MadhuR.Kamble,JosePatino,Massim-ilianoTodisco,andNicholasW.D.Evans,“Rawboost:Arawdataboostingandaugmentationmethodappliedtoautomaticspeakerverificationanti-spoofing,”inProc.ICASSP,2022,pp.6382–6386.[29]HongyiZhang,MoustaphaCiss´e,YannN.Dauphin,andDavidLopez-Paz,“Mixup:Beyondempiricalriskmini-mization,”inProc.ICLR,2018.[30]PierreForet,ArielKleiner,HosseinMobahi,andBehnamNeyshabur,“Sharpness-awareminimizationforefficientlyimprovinggeneralization,”inProc.ICLR,2021.[31]JungminKwon,JeongseopKim,HyunseoPark,andInKwonChoi,“ASAM:adaptivesharpness-awaremin-imizationforscale-invariantlearningofdeepneuralnet-works,”inProc.ICML,2021,vol.139,pp.5905–5914.[32]Hye-jinShim,Jee-weonJung,andTomiKinnunen,“Multi-datasetco-trainingwithsharpness-awareopti-mizationforaudioanti-spoofing,”inProc.Interspeech,2023,pp.3804–3808.[33]XingxuanZhang,RenzheXu,HanYu,HaoZou,andPengCui,“Gradientnormawareminimizationseeksfirst-orderflatnessandimprovesgeneralization,”inProc.CVPR,2023,pp.20247–20257.[34]NikoBr¨ummerandJohanA.duPreez,“Application-independentevaluationofspeakerdetection,”ComputerSpeech&Language,vol.20,no.2-3,pp.230–275,2006.[35]DiederikP.KingmaandJimmyBa,“Adam:Amethodforstochasticoptimization,”inProc.ICLR,2015.